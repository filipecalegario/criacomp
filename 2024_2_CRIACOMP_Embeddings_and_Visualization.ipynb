{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filipecalegario/criacomp/blob/main/2024_2_CRIACOMP_Embeddings_and_Visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "golEYAY3lHVj"
      },
      "source": [
        "# Word Embeddings, Semantic Search\n",
        "\n",
        "Word embeddings are a way of representing words and phrases as vectors. They can be used for a variety of tasks, including semantic search, anomaly detection, and classification. In the video on OpenAI Whisper, I mentioned how words whose vectors are numerically similar are also similar in semantic meaning. In this tutorial, we will learn how to implement semantic search using OpenAI embeddings. Understanding the Embeddings concept will be crucial to the next several videos in this series since we will use it to build several practical applications.\n",
        "\n",
        "Source: [Video 3 of this series](https://www.youtube.com/watch?v=LWYgjcZye1c)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KXdnqkoyK9H"
      },
      "source": [
        "# Read Data File Containing Words\n",
        "\n",
        "Now that we have configured OpenAI, let's start with a simple CSV file with familiar words. From here we'll build up to a more complex semantic search using sentences from the Fed speech. [Save the linked \"words.csv\" as a CSV](https://gist.github.com/hackingthemarkets/25240a55e463822d221539e79d91a8d0) and upload it to Google Colab. Once the file is uploaded, let's read it into a pandas dataframe using the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHJ-2gvfx9-J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('words.csv')\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwUiwvTmL71c"
      },
      "source": [
        "# Calculate Word Embeddings\n",
        "\n",
        "To use word embeddings for semantic search, you first compute the embeddings for a corpus of text using a word embedding algorithm. What does this mean? We are going to create a numerical representation of each of these words. To perform this computation, we'll use OpenAI's 'get_embedding' function.\n",
        "\n",
        "Since we have our words in a pandas dataframe, we can use \"apply\" to apply the get_embedding function to each row in the dataframe. We then store the calculated word embeddings in a new text file called \"word_embeddings.csv\" so that we don't have to call OpenAI again to perform these calculations."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI Text Embedding"
      ],
      "metadata": {
        "id": "co1w49CgSsii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get started, we will need to install and import OpenAI and input an API Key."
      ],
      "metadata": {
        "id": "Ynbqtmz3T8l0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUMmdUS_LPkI"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai\n",
        "\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "openAI_client = OpenAI(api_key = userdata.get('OPENAI_KEY'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding_openai(openai_client, input, model):\n",
        "  return openai_client.embeddings.create(input=input, model=model).data[0].embedding"
      ],
      "metadata": {
        "id": "cRJ75CHk3UDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jina Text Embedding"
      ],
      "metadata": {
        "id": "AR5zw4LQSxtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers\n",
        "from transformers import AutoModel\n",
        "\n",
        "jina_embedding_model = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-en', trust_remote_code=True) # trust_remote_code is needed to use the encode method\n",
        "#embeddings = jina_embedding_model.encode(['How is the weather today?', 'What is the current weather like today?'])"
      ],
      "metadata": {
        "id": "pVAR_-uYS0KQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding_jina(input):\n",
        "  return jina_embedding_model.encode(input).tolist()"
      ],
      "metadata": {
        "id": "-11nFy1uWYaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nomic Embed Text V2\n",
        "\n",
        "Based on the [Nomic Embed Text V2: An Open Source, Multilingual, Mixture-of-Experts Embedding Model](https://simonwillison.net/2025/Feb/12/nomic-embed-text-v2/)"
      ],
      "metadata": {
        "id": "5E4S2TiojNP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers"
      ],
      "metadata": {
        "id": "3fUj5wA3jpZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer(\"nomic-ai/nomic-embed-text-v2-moe\", trust_remote_code=True)\n",
        "\n",
        "def get_embedding_nomic(input):\n",
        "  return model.encode(input).tolist()"
      ],
      "metadata": {
        "id": "w7WNuxuVjW4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choosing the Embedding model"
      ],
      "metadata": {
        "id": "4vtGxISRUFoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(input):\n",
        "  # return get_embedding_jina(input)\n",
        "  return get_embedding_nomic(input)\n",
        "  #return get_embedding_openai(openAI_client, input, 'text-embedding-3-small')"
      ],
      "metadata": {
        "id": "tfZzcu3hUPXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVUez91kL5kY"
      },
      "outputs": [],
      "source": [
        "df['embedding'] = df['text'].apply(lambda x: get_embedding(x))\n",
        "df.to_csv('word_embeddings.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "8OvdNfOWVdFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2WjqR_PzMtg"
      },
      "source": [
        "# Semantic Search\n",
        "\n",
        "Now that we have our word embeddings stored, let's load them into a new dataframe and use it for semantic search. Since the 'embedding' in the CSV is stored as a string, we'll use apply() and to interpret this string as Python code and convert it to a numpy array so that we can perform calculations on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yM6N30oYeWhs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('word_embeddings.csv')\n",
        "df['embedding'] = df['embedding'].apply(eval).apply(np.array)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCtyD-yZz-6W"
      },
      "source": [
        "Let's now prompt ourselves for a search term that isn't in the dataframe. We'll use word embeddings to perform a semantic search for the words that are most similar to the word we entered. I'll first try the word \"hot dog\". Then we'll come back and try the word \"yellow\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtyaOReqzzn3"
      },
      "outputs": [],
      "source": [
        "search_term = input('Enter a search term: ')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpFRGaAX0H82"
      },
      "source": [
        "Now that we have a search term, let's calculate an embedding or vector for that search term using the OpenAI get_embedding function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrm5cxdDzfgU"
      },
      "outputs": [],
      "source": [
        "# semantic search\n",
        "search_term_vector = get_embedding(search_term)\n",
        "search_term_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVSNY0Ci0hB5"
      },
      "source": [
        " Once we have a vector representing that word, we can see how similar it is to other words in our dataframe by calculating the cosine similarity of our search term's word vector to each word embedding in our dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: https://platform.openai.com/docs/guides/embeddings/use-cases"
      ],
      "metadata": {
        "id": "y7hL4A6B487u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
      ],
      "metadata": {
        "id": "6UMIUUSg8C_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhE3ATG80oAt"
      },
      "outputs": [],
      "source": [
        "df[\"similarities\"] = df['embedding'].apply(lambda x: cosine_similarity(x, search_term_vector))\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsqkYbCD05TC"
      },
      "source": [
        "# Sorting By Similarity\n",
        "\n",
        "Now that we have calculated the similarities to each term in our dataframe, we simply sort the similarity values to find the terms that are most similar to the term we searched for. Notice how the foods are most similar to \"hot dog\". Not only that, it puts fast food closer to hot dog. Also some colors are ranked closer to hot dog than others. Let's go back and try the word \"yellow\" and walk through the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_4bDAkOg2m7"
      },
      "outputs": [],
      "source": [
        "df.sort_values(\"similarities\", ascending=False).head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LnJhZLK2pgz"
      },
      "source": [
        "# Adding Words Together\n",
        "\n",
        "What's even more interesting is that we can add word vectors together. What happens when we add the numbers for milk and espresso, then search for the word vector most similar to milk + espresso? Let's make a copy of the original dataframe and call it food_df. We'll operate on this copy. Let's try adding word together. Let's add milk + espresso and store the results in milk_espresso_vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CD-_nVUhGBH"
      },
      "outputs": [],
      "source": [
        "food_df = df.copy()\n",
        "\n",
        "milk_vector = food_df['embedding'][10]\n",
        "espresso_vector = food_df['embedding'][19]\n",
        "\n",
        "milk_espresso_vector = milk_vector + espresso_vector\n",
        "milk_espresso_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's find the words most similar to milk + espresso. If you have never done this before, it's pretty surprising that you can add words together like this and find similar words using numbers."
      ],
      "metadata": {
        "id": "PxlPom9m4nLB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3UCdDmJjfaQ"
      },
      "outputs": [],
      "source": [
        "food_df[\"similarities\"] = food_df['embedding'].apply(lambda x: cosine_similarity(x, milk_espresso_vector))\n",
        "food_df.sort_values(\"similarities\", ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing the Vectors"
      ],
      "metadata": {
        "id": "g_GLWR9_QpTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configurations"
      ],
      "metadata": {
        "id": "lE_kZgwu4GaD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNaC9jGDmaPn"
      },
      "source": [
        "!pip install -q umap-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQGgGfioRskp"
      },
      "source": [
        "from __future__ import print_function\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Javascript, HTML\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris, load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import umap\n",
        "import codecs, json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo5EWvq8R2dj"
      },
      "source": [
        "sns.set(style='white', context='notebook', rc={'figure.figsize':(14,10)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_sr8x_ESFLD"
      },
      "source": [
        "reducer = umap.UMAP(init='random')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reducer"
      ],
      "metadata": {
        "id": "NRtIFainOLe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions Definition"
      ],
      "metadata": {
        "id": "m2HvaKAh4rOf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtLlRS59SHK_"
      },
      "source": [
        "def run_umap(data, n_neighbors, min_dis, n_components, metric, spread):\n",
        "  reducer.n_neighbors = n_neighbors\n",
        "  reducer.min_dist = min_dis\n",
        "  reducer.n_components = n_components\n",
        "  reducer.metric = metric\n",
        "  reducer.spread = spread\n",
        "  embedding = reducer.fit_transform(data)\n",
        "  return embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BfZota4SLpH"
      },
      "source": [
        "def make_viz_embed(data, color = [], labels = []):\n",
        "  embed = f\"\"\"\n",
        "    <div id=\"observablehq-viewof-containerEl-96fe8cff\"></div>\n",
        "    <script type=\"module\">\n",
        "    import {{Runtime, Inspector}} from \"https://cdn.jsdelivr.net/npm/@observablehq/runtime@4/dist/runtime.js\";\n",
        "    import define from \"https://api.observablehq.com/@radames/umap-jupyter-notebook-scattergl.js?v=3\";\n",
        "    const inspect = new Inspector(document.querySelector(\"#observablehq-viewof-containerEl-96fe8cff\"));\n",
        "    const notebook = (new Runtime).module(define, name => {{\n",
        "    if(name === \"viewof containerEl\") return inspect;\n",
        "        return [\"init\"].includes(name);\n",
        "    }})\n",
        "    notebook.redefine('points', {json.dumps(data,separators=(',', ':'))})\n",
        "    notebook.redefine('colors', {json.dumps(colors,separators=(',', ':'))})\n",
        "    notebook.redefine('labels', {json.dumps(labels,separators=(',', ':'))})\n",
        "    </script>\n",
        "\n",
        "  \"\"\"\n",
        "  return embed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag_Ppl3_aFIi"
      },
      "source": [
        "def render(data, colors, labels, n_neighbors=100, min_dis=0.5, n_components=3, metric='euclidean', spread = 1.0):\n",
        "  embedding = run_umap(data, n_neighbors, min_dis, n_components, metric, spread)\n",
        "  html_str = make_viz_embed(embedding.tolist(), colors, labels)\n",
        "  display(HTML(html_str))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data"
      ],
      "metadata": {
        "id": "hP8WdxyM4SoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "casos_uso_df = pd.read_csv('word_embeddings.csv')"
      ],
      "metadata": {
        "id": "uW6B2uULPJmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "casos_uso_df.embedding = casos_uso_df.embedding.apply(eval).apply(np.array)"
      ],
      "metadata": {
        "id": "KUdOtUcBcbym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "casos_uso_df"
      ],
      "metadata": {
        "id": "MO1j_9tGcgwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "casos_uso_df.embedding"
      ],
      "metadata": {
        "id": "Rgd3Gm_OTQTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapting for the expected data format\n",
        "\n",
        "output_list = list()\n",
        "for n in casos_uso_df.embedding:\n",
        "  inter_output_line = list()\n",
        "  for m in n:\n",
        "    inter_output_line.append(m)\n",
        "  output_list.append(inter_output_line)\n",
        "\n",
        "output_list[0:1]"
      ],
      "metadata": {
        "id": "td-fXR00UXPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colors = [sns.color_palette()[0] for x in output_list]\n",
        "colors"
      ],
      "metadata": {
        "id": "1_lQt6zoVp5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "3Fzbja_l6gJZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uU8Cvx4Sw5_"
      },
      "source": [
        "render(output_list, colors, casos_uso_df['text'].to_list(), n_neighbors=3, min_dis=0.5, n_components=3, metric='cosine')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}