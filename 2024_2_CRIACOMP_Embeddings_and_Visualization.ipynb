{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filipecalegario/criacomp/blob/main/2024_2_CRIACOMP_Embeddings_and_Visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "golEYAY3lHVj"
      },
      "source": [
        "# OpenAI Word Embeddings, Semantic Search\n",
        "\n",
        "Word embeddings are a way of representing words and phrases as vectors. They can be used for a variety of tasks, including semantic search, anomaly detection, and classification. In the video on OpenAI Whisper, I mentioned how words whose vectors are numerically similar are also similar in semantic meaning. In this tutorial, we will learn how to implement semantic search using OpenAI embeddings. Understanding the Embeddings concept will be crucial to the next several videos in this series since we will use it to build several practical applications.\n",
        "\n",
        "To get started, we will need to install and import OpenAI and input an API Key. We learned how to do this in [Video 3 of this series](https://www.youtube.com/watch?v=LWYgjcZye1c)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AUMmdUS_LPkI"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai\n",
        "\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "openAI_client = OpenAI(api_key = userdata.get('OPENAI_KEY'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KXdnqkoyK9H"
      },
      "source": [
        "# Read Data File Containing Words\n",
        "\n",
        "Now that we have configured OpenAI, let's start with a simple CSV file with familiar words. From here we'll build up to a more complex semantic search using sentences from the Fed speech. [Save the linked \"words.csv\" as a CSV](https://gist.github.com/hackingthemarkets/25240a55e463822d221539e79d91a8d0) and upload it to Google Colab. Once the file is uploaded, let's read it into a pandas dataframe using the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rHJ-2gvfx9-J",
        "outputId": "2ea44105-8998-4f77-e288-561293f09ce6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             text\n",
            "0             red\n",
            "1        potatoes\n",
            "2            soda\n",
            "3          cheese\n",
            "4           water\n",
            "5            blue\n",
            "6          crispy\n",
            "7       hamburger\n",
            "8          coffee\n",
            "9           green\n",
            "10           milk\n",
            "11       la croix\n",
            "12         yellow\n",
            "13      chocolate\n",
            "14   french fries\n",
            "15          latte\n",
            "16           cake\n",
            "17          brown\n",
            "18   cheeseburger\n",
            "19       espresso\n",
            "20     cheesecake\n",
            "21          black\n",
            "22          mocha\n",
            "23          fizzy\n",
            "24         carbon\n",
            "25         banana\n",
            "26        saudade\n",
            "27        longing\n",
            "28       feelings\n",
            "29  baião de dois\n",
            "30        buchada\n",
            "31         cuscuz\n",
            "32          verde\n",
            "33        amarelo\n",
            "34          rouge\n",
            "35   luiz gonzaga\n",
            "36            aoi\n",
            "37      tartaruga\n",
            "38          zebra\n",
            "39         girafa\n",
            "40        giraffe\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('words.csv')\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwUiwvTmL71c"
      },
      "source": [
        "# Calculate Word Embeddings\n",
        "\n",
        "To use word embeddings for semantic search, you first compute the embeddings for a corpus of text using a word embedding algorithm. What does this mean? We are going to create a numerical representation of each of these words. To perform this computation, we'll use OpenAI's 'get_embedding' function.\n",
        "\n",
        "Since we have our words in a pandas dataframe, we can use \"apply\" to apply the get_embedding function to each row in the dataframe. We then store the calculated word embeddings in a new text file called \"word_embeddings.csv\" so that we don't have to call OpenAI again to perform these calculations."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI Text Embedding"
      ],
      "metadata": {
        "id": "co1w49CgSsii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(openai_client, input, model):\n",
        "  return openai_client.embeddings.create(input=input, model=model).data[0].embedding"
      ],
      "metadata": {
        "id": "cRJ75CHk3UDi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jina Text Embedding"
      ],
      "metadata": {
        "id": "AR5zw4LQSxtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "from transformers import AutoModel\n",
        "\n",
        "jina_embedding_model = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-en', trust_remote_code=True) # trust_remote_code is needed to use the encode method\n",
        "#embeddings = jina_embedding_model.encode(['How is the weather today?', 'What is the current weather like today?'])\n",
        "\n",
        "def get_embedding_jina(input):\n",
        "  return jina_embedding_model.encode(input)"
      ],
      "metadata": {
        "id": "pVAR_-uYS0KQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CVUez91kL5kY"
      },
      "outputs": [],
      "source": [
        "df['embedding'] = df['text'].apply(lambda x: get_embedding(client, x, 'text-embedding-3-small'))\n",
        "df.to_csv('word_embeddings.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2WjqR_PzMtg"
      },
      "source": [
        "# Semantic Search\n",
        "\n",
        "Now that we have our word embeddings stored, let's load them into a new dataframe and use it for semantic search. Since the 'embedding' in the CSV is stored as a string, we'll use apply() and to interpret this string as Python code and convert it to a numpy array so that we can perform calculations on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yM6N30oYeWhs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('word_embeddings.csv')\n",
        "df['embedding'] = df['embedding'].apply(eval).apply(np.array)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCtyD-yZz-6W"
      },
      "source": [
        "Let's now prompt ourselves for a search term that isn't in the dataframe. We'll use word embeddings to perform a semantic search for the words that are most similar to the word we entered. I'll first try the word \"hot dog\". Then we'll come back and try the word \"yellow\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtyaOReqzzn3"
      },
      "outputs": [],
      "source": [
        "search_term = input('Enter a search term: ')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpFRGaAX0H82"
      },
      "source": [
        "Now that we have a search term, let's calculate an embedding or vector for that search term using the OpenAI get_embedding function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrm5cxdDzfgU"
      },
      "outputs": [],
      "source": [
        "# semantic search\n",
        "search_term_vector = get_embedding(client, search_term, \"text-embedding-3-small\")\n",
        "search_term_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVSNY0Ci0hB5"
      },
      "source": [
        " Once we have a vector representing that word, we can see how similar it is to other words in our dataframe by calculating the cosine similarity of our search term's word vector to each word embedding in our dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: https://platform.openai.com/docs/guides/embeddings/use-cases"
      ],
      "metadata": {
        "id": "y7hL4A6B487u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
      ],
      "metadata": {
        "id": "6UMIUUSg8C_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhE3ATG80oAt"
      },
      "outputs": [],
      "source": [
        "df[\"similarities\"] = df['embedding'].apply(lambda x: cosine_similarity(x, search_term_vector))\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsqkYbCD05TC"
      },
      "source": [
        "# Sorting By Similarity\n",
        "\n",
        "Now that we have calculated the similarities to each term in our dataframe, we simply sort the similarity values to find the terms that are most similar to the term we searched for. Notice how the foods are most similar to \"hot dog\". Not only that, it puts fast food closer to hot dog. Also some colors are ranked closer to hot dog than others. Let's go back and try the word \"yellow\" and walk through the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_4bDAkOg2m7"
      },
      "outputs": [],
      "source": [
        "df.sort_values(\"similarities\", ascending=False).head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LnJhZLK2pgz"
      },
      "source": [
        "# Adding Words Together\n",
        "\n",
        "What's even more interesting is that we can add word vectors together. What happens when we add the numbers for milk and espresso, then search for the word vector most similar to milk + espresso? Let's make a copy of the original dataframe and call it food_df. We'll operate on this copy. Let's try adding word together. Let's add milk + espresso and store the results in milk_espresso_vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CD-_nVUhGBH"
      },
      "outputs": [],
      "source": [
        "food_df = df.copy()\n",
        "\n",
        "milk_vector = food_df['embedding'][10]\n",
        "espresso_vector = food_df['embedding'][19]\n",
        "\n",
        "milk_espresso_vector = milk_vector + espresso_vector\n",
        "milk_espresso_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's find the words most similar to milk + espresso. If you have never done this before, it's pretty surprising that you can add words together like this and find similar words using numbers."
      ],
      "metadata": {
        "id": "PxlPom9m4nLB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3UCdDmJjfaQ"
      },
      "outputs": [],
      "source": [
        "food_df[\"similarities\"] = food_df['embedding'].apply(lambda x: cosine_similarity(x, milk_espresso_vector))\n",
        "food_df.sort_values(\"similarities\", ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zfp3tgRsQHFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing the Vectors"
      ],
      "metadata": {
        "id": "g_GLWR9_QpTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configurations"
      ],
      "metadata": {
        "id": "lE_kZgwu4GaD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNaC9jGDmaPn",
        "outputId": "dae373db-d769-4705-f8f8-1989ee595d80"
      },
      "source": [
        "%pip install umap-learn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting umap-learn\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.10.1)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.56.4)\n",
            "Collecting pynndescent>=0.5 (from umap-learn)\n",
            "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.66.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn) (67.7.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.2.0)\n",
            "Building wheels for collected packages: umap-learn, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82808 sha256=ec2c8c6ec8e1314b7de812a390cbacaa6522b15f2f5a1584f650c11c3b05ae41\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/e8/c6/a37ea663620bd5200ea1ba0907ab3c217042c1d035ef606acc\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55617 sha256=b78f88c8f251ff1f78855535c82a49889391f284f8c692151832eb2355f2e467\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
            "Successfully built umap-learn pynndescent\n",
            "Installing collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.10 umap-learn-0.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQGgGfioRskp"
      },
      "source": [
        "from __future__ import print_function\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Javascript, HTML\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris, load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import umap\n",
        "import codecs, json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo5EWvq8R2dj"
      },
      "source": [
        "sns.set(style='white', context='notebook', rc={'figure.figsize':(14,10)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_sr8x_ESFLD"
      },
      "source": [
        "reducer = umap.UMAP(init='random')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reducer"
      ],
      "metadata": {
        "id": "NRtIFainOLe8",
        "outputId": "331f4e76-2a75-4fe9-9c51-b658d0b7baab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UMAP(init='random')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>UMAP(init=&#x27;random&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">UMAP</label><div class=\"sk-toggleable__content\"><pre>UMAP(init=&#x27;random&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions Definition"
      ],
      "metadata": {
        "id": "m2HvaKAh4rOf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtLlRS59SHK_"
      },
      "source": [
        "def run_umap(data, n_neighbors, min_dis, n_components, metric, spread):\n",
        "  reducer.n_neighbors = n_neighbors\n",
        "  reducer.min_dist = min_dis\n",
        "  reducer.n_components = n_components\n",
        "  reducer.metric = metric\n",
        "  reducer.spread = spread\n",
        "  embedding = reducer.fit_transform(data)\n",
        "  return embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BfZota4SLpH"
      },
      "source": [
        "def make_viz_embed(data, color = [], labels = []):\n",
        "  embed = f\"\"\"\n",
        "    <div id=\"observablehq-viewof-containerEl-96fe8cff\"></div>\n",
        "    <script type=\"module\">\n",
        "    import {{Runtime, Inspector}} from \"https://cdn.jsdelivr.net/npm/@observablehq/runtime@4/dist/runtime.js\";\n",
        "    import define from \"https://api.observablehq.com/@radames/umap-jupyter-notebook-scattergl.js?v=3\";\n",
        "    const inspect = new Inspector(document.querySelector(\"#observablehq-viewof-containerEl-96fe8cff\"));\n",
        "    const notebook = (new Runtime).module(define, name => {{\n",
        "    if(name === \"viewof containerEl\") return inspect;\n",
        "        return [\"init\"].includes(name);\n",
        "    }})\n",
        "    notebook.redefine('points', {json.dumps(data,separators=(',', ':'))})\n",
        "    notebook.redefine('colors', {json.dumps(colors,separators=(',', ':'))})\n",
        "    notebook.redefine('labels', {json.dumps(labels,separators=(',', ':'))})\n",
        "    </script>\n",
        "\n",
        "  \"\"\"\n",
        "  return embed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag_Ppl3_aFIi"
      },
      "source": [
        "def render(data, colors, labels, n_neighbors=100, min_dis=0.5, n_components=3, metric='euclidean', spread = 1.0):\n",
        "  embedding = run_umap(data, n_neighbors, min_dis, n_components, metric, spread)\n",
        "  html_str = make_viz_embed(embedding.tolist(), colors, labels)\n",
        "  display(HTML(html_str))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data"
      ],
      "metadata": {
        "id": "hP8WdxyM4SoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "casos_uso_df = pd.read_csv('word_embeddings.csv')"
      ],
      "metadata": {
        "id": "uW6B2uULPJmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "casos_uso_df.embedding = casos_uso_df.embedding.apply(eval).apply(np.array)"
      ],
      "metadata": {
        "id": "KUdOtUcBcbym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "casos_uso_df"
      ],
      "metadata": {
        "id": "MO1j_9tGcgwt",
        "outputId": "c59ed255-7edb-449a-d8be-e1545b034d0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0                                 Itens      Categoria  \\\n",
              "0             0                             Midjouney   \"aplicacoes\"   \n",
              "1             1                           Openjourney   \"aplicacoes\"   \n",
              "2             2                                DALL E   \"aplicacoes\"   \n",
              "3             3                              Tome.app   \"aplicacoes\"   \n",
              "4             4                      Stable diffusion   \"aplicacoes\"   \n",
              "..          ...                                   ...            ...   \n",
              "203         203  Identificação de falhas de segurança    \"casos_uso\"   \n",
              "204         204     Fake news para manipular eleições    \"casos_uso\"   \n",
              "205         205            Geração de planos de crime    \"casos_uso\"   \n",
              "206         206               Nova trending do tiktok    \"casos_uso\"   \n",
              "207         207                             Rationale    \"casos_uso\"   \n",
              "\n",
              "                                             embedding  \n",
              "0    [-0.009065642952919006, -0.021264266222715378,...  \n",
              "1    [-0.0028128710109740496, -0.002215629443526268...  \n",
              "2    [-0.011047448962926865, -0.021905938163399696,...  \n",
              "3    [0.003620806382969022, 0.006396056618541479, 0...  \n",
              "4    [-0.01985820196568966, 0.016730502247810364, 0...  \n",
              "..                                                 ...  \n",
              "203  [-0.015269014053046703, 0.009737345390021801, ...  \n",
              "204  [-0.030033115297555923, 0.02663939818739891, -...  \n",
              "205  [-0.008206862024962902, -0.015600252896547318,...  \n",
              "206  [-0.03929344564676285, -0.008771595545113087, ...  \n",
              "207  [-0.0017149465857073665, -0.014608925208449364...  \n",
              "\n",
              "[208 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9fa5ef1c-dd5f-433f-a9f7-77bee1ffcd59\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Itens</th>\n",
              "      <th>Categoria</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Midjouney</td>\n",
              "      <td>\"aplicacoes\"</td>\n",
              "      <td>[-0.009065642952919006, -0.021264266222715378,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Openjourney</td>\n",
              "      <td>\"aplicacoes\"</td>\n",
              "      <td>[-0.0028128710109740496, -0.002215629443526268...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>DALL E</td>\n",
              "      <td>\"aplicacoes\"</td>\n",
              "      <td>[-0.011047448962926865, -0.021905938163399696,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Tome.app</td>\n",
              "      <td>\"aplicacoes\"</td>\n",
              "      <td>[0.003620806382969022, 0.006396056618541479, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Stable diffusion</td>\n",
              "      <td>\"aplicacoes\"</td>\n",
              "      <td>[-0.01985820196568966, 0.016730502247810364, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>203</td>\n",
              "      <td>Identificação de falhas de segurança</td>\n",
              "      <td>\"casos_uso\"</td>\n",
              "      <td>[-0.015269014053046703, 0.009737345390021801, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>204</td>\n",
              "      <td>Fake news para manipular eleições</td>\n",
              "      <td>\"casos_uso\"</td>\n",
              "      <td>[-0.030033115297555923, 0.02663939818739891, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>205</td>\n",
              "      <td>Geração de planos de crime</td>\n",
              "      <td>\"casos_uso\"</td>\n",
              "      <td>[-0.008206862024962902, -0.015600252896547318,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>206</td>\n",
              "      <td>Nova trending do tiktok</td>\n",
              "      <td>\"casos_uso\"</td>\n",
              "      <td>[-0.03929344564676285, -0.008771595545113087, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>207</td>\n",
              "      <td>Rationale</td>\n",
              "      <td>\"casos_uso\"</td>\n",
              "      <td>[-0.0017149465857073665, -0.014608925208449364...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>208 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9fa5ef1c-dd5f-433f-a9f7-77bee1ffcd59')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9fa5ef1c-dd5f-433f-a9f7-77bee1ffcd59 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9fa5ef1c-dd5f-433f-a9f7-77bee1ffcd59');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1957f6ed-60ad-4b61-9969-04ac387e07b2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1957f6ed-60ad-4b61-9969-04ac387e07b2')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1957f6ed-60ad-4b61-9969-04ac387e07b2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "casos_uso_df.embedding"
      ],
      "metadata": {
        "id": "Rgd3Gm_OTQTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapting for the expected data format\n",
        "\n",
        "output_list = list()\n",
        "for n in casos_uso_df.embedding:\n",
        "  inter_output_line = list()\n",
        "  for m in n:\n",
        "    inter_output_line.append(m)\n",
        "  output_list.append(inter_output_line)\n",
        "\n",
        "output_list[0:1]"
      ],
      "metadata": {
        "id": "td-fXR00UXPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colors = [sns.color_palette()[0] for x in output_list]\n",
        "colors"
      ],
      "metadata": {
        "id": "1_lQt6zoVp5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "3Fzbja_l6gJZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uU8Cvx4Sw5_"
      },
      "source": [
        "render(output_list, colors, casos_uso_df['Itens'].to_list(), n_neighbors=3, min_dis=0.5, n_components=3, metric='cosine')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}