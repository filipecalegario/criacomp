{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filipecalegario/criacomp/blob/main/2024_2_CRIACOMP_Embeddings_and_Visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "golEYAY3lHVj"
      },
      "source": [
        "# Word Embeddings, Semantic Search\n",
        "\n",
        "Word embeddings are a way of representing words and phrases as vectors. They can be used for a variety of tasks, including semantic search, anomaly detection, and classification. In the video on OpenAI Whisper, I mentioned how words whose vectors are numerically similar are also similar in semantic meaning. In this tutorial, we will learn how to implement semantic search using OpenAI embeddings. Understanding the Embeddings concept will be crucial to the next several videos in this series since we will use it to build several practical applications.\n",
        "\n",
        "Source: [Video 3 of this series](https://www.youtube.com/watch?v=LWYgjcZye1c)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KXdnqkoyK9H"
      },
      "source": [
        "# Read Data File Containing Words\n",
        "\n",
        "Now that we have configured OpenAI, let's start with a simple CSV file with familiar words. From here we'll build up to a more complex semantic search using sentences from the Fed speech. [Save the linked \"words.csv\" as a CSV](https://gist.github.com/hackingthemarkets/25240a55e463822d221539e79d91a8d0) and upload it to Google Colab. Once the file is uploaded, let's read it into a pandas dataframe using the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rHJ-2gvfx9-J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e720e50-432f-45a6-bf0c-9fb9dc3a6ea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             text\n",
            "0             red\n",
            "1        potatoes\n",
            "2            soda\n",
            "3          cheese\n",
            "4           water\n",
            "5            blue\n",
            "6          crispy\n",
            "7       hamburger\n",
            "8          coffee\n",
            "9           green\n",
            "10           milk\n",
            "11       la croix\n",
            "12         yellow\n",
            "13      chocolate\n",
            "14   french fries\n",
            "15          latte\n",
            "16           cake\n",
            "17          brown\n",
            "18   cheeseburger\n",
            "19       espresso\n",
            "20     cheesecake\n",
            "21          black\n",
            "22          mocha\n",
            "23          fizzy\n",
            "24         carbon\n",
            "25         banana\n",
            "26        saudade\n",
            "27        longing\n",
            "28       feelings\n",
            "29  baião de dois\n",
            "30        buchada\n",
            "31         cuscuz\n",
            "32          verde\n",
            "33        amarelo\n",
            "34          rouge\n",
            "35   luiz gonzaga\n",
            "36            aoi\n",
            "37      tartaruga\n",
            "38          zebra\n",
            "39         girafa\n",
            "40        giraffe\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('words.csv')\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwUiwvTmL71c"
      },
      "source": [
        "# Calculate Word Embeddings\n",
        "\n",
        "To use word embeddings for semantic search, you first compute the embeddings for a corpus of text using a word embedding algorithm. What does this mean? We are going to create a numerical representation of each of these words. To perform this computation, we'll use OpenAI's 'get_embedding' function.\n",
        "\n",
        "Since we have our words in a pandas dataframe, we can use \"apply\" to apply the get_embedding function to each row in the dataframe. We then store the calculated word embeddings in a new text file called \"word_embeddings.csv\" so that we don't have to call OpenAI again to perform these calculations."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI Text Embedding"
      ],
      "metadata": {
        "id": "co1w49CgSsii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get started, we will need to install and import OpenAI and input an API Key."
      ],
      "metadata": {
        "id": "Ynbqtmz3T8l0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AUMmdUS_LPkI"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai\n",
        "\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "openAI_client = OpenAI(api_key = userdata.get('OPENAI_KEY'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding_openai(openai_client, input, model):\n",
        "  return openai_client.embeddings.create(input=input, model=model).data[0].embedding"
      ],
      "metadata": {
        "id": "cRJ75CHk3UDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jina Text Embedding"
      ],
      "metadata": {
        "id": "AR5zw4LQSxtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers\n",
        "from transformers import AutoModel\n",
        "\n",
        "jina_embedding_model = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-en', trust_remote_code=True) # trust_remote_code is needed to use the encode method\n",
        "#embeddings = jina_embedding_model.encode(['How is the weather today?', 'What is the current weather like today?'])"
      ],
      "metadata": {
        "id": "pVAR_-uYS0KQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding_jina(input):\n",
        "  return jina_embedding_model.encode(input).tolist()"
      ],
      "metadata": {
        "id": "-11nFy1uWYaf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choosing the Embedding model"
      ],
      "metadata": {
        "id": "4vtGxISRUFoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(input):\n",
        "  return get_embedding_jina(input)\n",
        "  #return get_embedding_openai(openAI_client, input, 'text-embedding-3-small')"
      ],
      "metadata": {
        "id": "tfZzcu3hUPXm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CVUez91kL5kY"
      },
      "outputs": [],
      "source": [
        "df['embedding'] = df['text'].apply(lambda x: get_embedding(x))\n",
        "df.to_csv('word_embeddings.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "8OvdNfOWVdFx",
        "outputId": "210d9a23-a26d-44b8-bfca-8ef1a9ba7be7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Unnamed: 0           text  \\\n",
              "0            0            red   \n",
              "1            1       potatoes   \n",
              "2            2           soda   \n",
              "3            3         cheese   \n",
              "4            4          water   \n",
              "5            5           blue   \n",
              "6            6         crispy   \n",
              "7            7      hamburger   \n",
              "8            8         coffee   \n",
              "9            9          green   \n",
              "10          10           milk   \n",
              "11          11       la croix   \n",
              "12          12         yellow   \n",
              "13          13      chocolate   \n",
              "14          14   french fries   \n",
              "15          15          latte   \n",
              "16          16           cake   \n",
              "17          17          brown   \n",
              "18          18   cheeseburger   \n",
              "19          19       espresso   \n",
              "20          20     cheesecake   \n",
              "21          21          black   \n",
              "22          22          mocha   \n",
              "23          23          fizzy   \n",
              "24          24         carbon   \n",
              "25          25         banana   \n",
              "26          26        saudade   \n",
              "27          27        longing   \n",
              "28          28       feelings   \n",
              "29          29  baião de dois   \n",
              "30          30        buchada   \n",
              "31          31         cuscuz   \n",
              "32          32          verde   \n",
              "33          33        amarelo   \n",
              "34          34          rouge   \n",
              "35          35   luiz gonzaga   \n",
              "36          36            aoi   \n",
              "37          37      tartaruga   \n",
              "38          38          zebra   \n",
              "39          39         girafa   \n",
              "40          40        giraffe   \n",
              "\n",
              "                                            embedding  \n",
              "0   [-0.45700905  0.08197942  0.39368343  0.624485...  \n",
              "1   [-3.26606840e-01 -5.24763703e-01  5.63539565e-...  \n",
              "2   [ 0.29684895 -0.5071297   0.45251417  0.577882...  \n",
              "3   [-5.37811406e-02 -1.18773627e+00  7.13873565e-...  \n",
              "4   [-4.03747447e-02 -5.89734495e-01  6.59245551e-...  \n",
              "5   [-3.68058354e-01  2.37847984e-01  4.78111178e-...  \n",
              "6   [ 6.34654760e-02 -5.29833853e-01  1.83781654e-...  \n",
              "7   [-0.35171175 -1.0410031   0.38903752  0.021174...  \n",
              "8   [ 1.90639094e-01 -7.63770103e-01  6.54947758e-...  \n",
              "9   [-1.56025201e-01 -1.89577326e-01  6.37714088e-...  \n",
              "10  [ 3.80071312e-01 -8.24058712e-01  2.12192237e-...  \n",
              "11  [ 3.72821748e-01 -1.13495970e+00  7.64294386e-...  \n",
              "12  [-1.55941084e-01  8.28413367e-02  3.36470515e-...  \n",
              "13  [ 1.21313035e-01 -9.08200204e-01  3.17704171e-...  \n",
              "14  [-4.87111121e-01 -8.12439740e-01  4.66372401e-...  \n",
              "15  [ 3.82162690e-01 -1.14835525e+00  5.43662965e-...  \n",
              "16  [-0.17395961 -0.8312592   0.42556152  0.874340...  \n",
              "17  [-4.14390296e-01 -4.81137276e-01  6.14322543e-...  \n",
              "18  [-4.51336384e-01 -9.19861615e-01  2.16809183e-...  \n",
              "19  [ 1.52074173e-03 -6.20279193e-01  6.41284943e-...  \n",
              "20  [-3.36625636e-01 -7.84353793e-01  3.55162233e-...  \n",
              "21  [-4.11426932e-01 -1.98186681e-01  5.47483742e-...  \n",
              "22  [ 0.28675267 -0.82057744  0.43658295  0.702699...  \n",
              "23  [ 8.17252696e-02 -8.86815310e-01  3.68738025e-...  \n",
              "24  [-0.2867788  -0.44015834  0.96815014 -0.275895...  \n",
              "25  [-2.96988517e-01 -7.18042850e-01  4.51450974e-...  \n",
              "26  [-1.15051612e-01 -3.32931727e-01  2.10172623e-...  \n",
              "27  [-2.23353386e-01  1.25246629e-01  8.97710323e-...  \n",
              "28  [-4.90437537e-01 -1.32911637e-01  8.49351585e-...  \n",
              "29  [ 1.93759948e-01 -5.50929010e-01  6.71338201e-...  \n",
              "30  [ 3.55325714e-02 -5.43621838e-01  3.48260552e-...  \n",
              "31  [-7.58136362e-02 -9.08231437e-01  5.82066059e-...  \n",
              "32  [-0.21679024 -0.28530192  0.46356067  0.305028...  \n",
              "33  [-2.99638212e-01 -3.02231818e-01  6.42290592e-...  \n",
              "34  [ 2.69145340e-01 -5.61931074e-01  7.44589388e-...  \n",
              "35  [ 0.04697792 -0.9198486   0.6980131   0.502312...  \n",
              "36  [-2.75150426e-02 -3.09554994e-01  5.97614527e-...  \n",
              "37  [-3.73845808e-02 -4.74155128e-01  5.44274926e-...  \n",
              "38  [-6.71598613e-01 -4.53743696e-01 -1.21977134e-...  \n",
              "39  [-5.25743663e-01 -8.76003742e-01 -7.65430033e-...  \n",
              "40  [-5.44020236e-01 -7.38521934e-01 -7.41994008e-...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-729693ab-c314-4002-a545-382fdbab70fb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>red</td>\n",
              "      <td>[-0.45700905  0.08197942  0.39368343  0.624485...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>potatoes</td>\n",
              "      <td>[-3.26606840e-01 -5.24763703e-01  5.63539565e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>soda</td>\n",
              "      <td>[ 0.29684895 -0.5071297   0.45251417  0.577882...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>cheese</td>\n",
              "      <td>[-5.37811406e-02 -1.18773627e+00  7.13873565e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>water</td>\n",
              "      <td>[-4.03747447e-02 -5.89734495e-01  6.59245551e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>blue</td>\n",
              "      <td>[-3.68058354e-01  2.37847984e-01  4.78111178e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>crispy</td>\n",
              "      <td>[ 6.34654760e-02 -5.29833853e-01  1.83781654e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>hamburger</td>\n",
              "      <td>[-0.35171175 -1.0410031   0.38903752  0.021174...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>coffee</td>\n",
              "      <td>[ 1.90639094e-01 -7.63770103e-01  6.54947758e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>green</td>\n",
              "      <td>[-1.56025201e-01 -1.89577326e-01  6.37714088e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>milk</td>\n",
              "      <td>[ 3.80071312e-01 -8.24058712e-01  2.12192237e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>la croix</td>\n",
              "      <td>[ 3.72821748e-01 -1.13495970e+00  7.64294386e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>yellow</td>\n",
              "      <td>[-1.55941084e-01  8.28413367e-02  3.36470515e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>chocolate</td>\n",
              "      <td>[ 1.21313035e-01 -9.08200204e-01  3.17704171e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>french fries</td>\n",
              "      <td>[-4.87111121e-01 -8.12439740e-01  4.66372401e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>latte</td>\n",
              "      <td>[ 3.82162690e-01 -1.14835525e+00  5.43662965e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>cake</td>\n",
              "      <td>[-0.17395961 -0.8312592   0.42556152  0.874340...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>brown</td>\n",
              "      <td>[-4.14390296e-01 -4.81137276e-01  6.14322543e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>cheeseburger</td>\n",
              "      <td>[-4.51336384e-01 -9.19861615e-01  2.16809183e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>espresso</td>\n",
              "      <td>[ 1.52074173e-03 -6.20279193e-01  6.41284943e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>cheesecake</td>\n",
              "      <td>[-3.36625636e-01 -7.84353793e-01  3.55162233e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>black</td>\n",
              "      <td>[-4.11426932e-01 -1.98186681e-01  5.47483742e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>mocha</td>\n",
              "      <td>[ 0.28675267 -0.82057744  0.43658295  0.702699...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>fizzy</td>\n",
              "      <td>[ 8.17252696e-02 -8.86815310e-01  3.68738025e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>carbon</td>\n",
              "      <td>[-0.2867788  -0.44015834  0.96815014 -0.275895...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>banana</td>\n",
              "      <td>[-2.96988517e-01 -7.18042850e-01  4.51450974e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>saudade</td>\n",
              "      <td>[-1.15051612e-01 -3.32931727e-01  2.10172623e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27</td>\n",
              "      <td>longing</td>\n",
              "      <td>[-2.23353386e-01  1.25246629e-01  8.97710323e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>feelings</td>\n",
              "      <td>[-4.90437537e-01 -1.32911637e-01  8.49351585e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>29</td>\n",
              "      <td>baião de dois</td>\n",
              "      <td>[ 1.93759948e-01 -5.50929010e-01  6.71338201e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>30</td>\n",
              "      <td>buchada</td>\n",
              "      <td>[ 3.55325714e-02 -5.43621838e-01  3.48260552e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>31</td>\n",
              "      <td>cuscuz</td>\n",
              "      <td>[-7.58136362e-02 -9.08231437e-01  5.82066059e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>32</td>\n",
              "      <td>verde</td>\n",
              "      <td>[-0.21679024 -0.28530192  0.46356067  0.305028...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>33</td>\n",
              "      <td>amarelo</td>\n",
              "      <td>[-2.99638212e-01 -3.02231818e-01  6.42290592e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>34</td>\n",
              "      <td>rouge</td>\n",
              "      <td>[ 2.69145340e-01 -5.61931074e-01  7.44589388e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>35</td>\n",
              "      <td>luiz gonzaga</td>\n",
              "      <td>[ 0.04697792 -0.9198486   0.6980131   0.502312...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>36</td>\n",
              "      <td>aoi</td>\n",
              "      <td>[-2.75150426e-02 -3.09554994e-01  5.97614527e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>37</td>\n",
              "      <td>tartaruga</td>\n",
              "      <td>[-3.73845808e-02 -4.74155128e-01  5.44274926e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>38</td>\n",
              "      <td>zebra</td>\n",
              "      <td>[-6.71598613e-01 -4.53743696e-01 -1.21977134e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>39</td>\n",
              "      <td>girafa</td>\n",
              "      <td>[-5.25743663e-01 -8.76003742e-01 -7.65430033e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>40</td>\n",
              "      <td>giraffe</td>\n",
              "      <td>[-5.44020236e-01 -7.38521934e-01 -7.41994008e-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-729693ab-c314-4002-a545-382fdbab70fb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-729693ab-c314-4002-a545-382fdbab70fb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-729693ab-c314-4002-a545-382fdbab70fb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-85959083-49ac-4fdf-a91e-72a4fea6d5c5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-85959083-49ac-4fdf-a91e-72a4fea6d5c5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-85959083-49ac-4fdf-a91e-72a4fea6d5c5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e86387dd-cb51-434d-b423-2bd83c957390\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e86387dd-cb51-434d-b423-2bd83c957390 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 41,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 0,\n        \"max\": 40,\n        \"num_unique_values\": 41,\n        \"samples\": [\n          24,\n          13,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 41,\n        \"samples\": [\n          \"carbon\",\n          \"chocolate\",\n          \"coffee\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedding\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 41,\n        \"samples\": [\n          \"[-0.2867788  -0.44015834  0.96815014 -0.27589545 -0.10088529  0.9049599\\n  0.17146485 -0.19088781  0.83727837  0.7038448  -0.31417236 -0.35645708\\n -0.6830012   0.06876046 -0.12878451  0.8308546   0.15219624  0.14497893\\n  0.16488093 -0.11275104 -0.22395884 -0.45237306 -1.2390872  -0.5046515\\n  0.8607499   0.8252747   1.0511855  -0.07722765  0.04470753  0.9717633\\n -0.24631332 -0.3352299  -0.3019936  -0.1570789  -0.28981218 -0.31660002\\n -0.18543305 -0.44118968 -0.02332383  0.9709757   0.31181273  0.02433144\\n -0.12403046  0.62755615 -0.7816722   0.36206493 -0.23343515 -0.33445263\\n  0.22977787 -0.14935125 -0.17929453 -0.66358155 -0.5636594  -1.112381\\n  0.27525565  0.52082545  0.747487   -0.07623205 -0.4782791  -0.7129839\\n -0.6191953   0.6612353   0.15401313  0.9548288   0.4295212  -0.08493298\\n -0.24146892 -1.0649753  -0.7685468  -0.24998863  0.01034697  0.28642982\\n  0.1899972   0.05010477 -0.52308863  0.6272151  -0.31103405 -0.28980863\\n -0.9136571  -0.44059083  0.61482435  0.25888544  0.57882786  0.16029863\\n -0.11491828 -0.27739397 -0.6023791  -0.16118401  1.0751028   0.44288704\\n -0.38893604  1.3876771   0.21588485  0.42020178 -0.12659995  0.63038206\\n -0.17836048 -0.66311556 -0.3672425   0.780205    0.22907622  0.5335106\\n -0.04291354 -0.21531995  0.32555997  0.42327932 -0.02820879 -0.9574151\\n -1.0281794   0.64490634 -0.24585609 -0.24615397  0.49289647 -0.66459626\\n -0.3683958  -0.21596675 -0.3168026   0.02762103 -0.4234035   0.5964887\\n -0.4412575  -0.18603987  0.58982235 -1.0211794   0.6406338   0.42203656\\n  0.6206044   0.07340698  0.4042109  -0.06515304  0.02683212 -0.8828259\\n  0.55110925 -0.4778799  -0.9291447  -0.56057745  0.8032577   0.5058126\\n -0.32577312 -0.13922901 -0.8155926   0.5604189  -0.5088112  -0.17794174\\n -0.41020146 -0.5866203  -0.7094241   1.035233    0.78353184 -0.76264447\\n  0.6516523  -0.5109306  -0.2470438   0.5098112   0.04100059 -0.17626713\\n  0.01968979 -0.5201793  -0.27357954 -0.2706925  -0.31387523 -0.86545706\\n -0.5735008  -0.2674627   0.05804579  0.97804856  0.4327285   0.15137517\\n -0.04378739 -0.84717363  0.12098379  0.17307647 -0.50844175 -0.2521839\\n -0.07154994  0.32206368  0.01606216  0.1397296  -1.0814439  -0.03116241\\n -0.28428417  0.6420329   0.7898087   0.7413831   0.08356435 -0.27233028\\n  0.5255825  -0.14573789 -0.3550144   0.41250643 -0.21802323 -0.7702907\\n  0.01918709  0.08831016  0.1798615  -0.8030587   0.9732926   0.06683049\\n -0.38580525  0.01516778  0.5022078  -0.4458892  -0.22288883 -0.26659548\\n -0.3169895  -0.35167623 -0.56944567  0.05925502 -0.8312121  -0.02426654\\n  0.50298715  0.6795292  -0.44668087  0.8661022  -1.2995962   0.0387655\\n  0.10602232  0.27545255  0.14464338  0.60687786  0.3368248  -0.7520687\\n -0.90517217  0.27137682 -0.10836831  0.44940948 -0.05355237 -0.1248129\\n  0.09870449  0.50189024  0.03188537  0.5255763   0.7041989  -0.8789422\\n  0.32400706 -0.36650395  0.7578165  -0.84381914  0.15238865 -0.47159633\\n -0.4432294   0.13466452 -0.6630809  -0.60516906 -0.69662786 -0.90919834\\n  0.7076354  -0.44945255 -0.05218123 -0.54982895 -0.1256257   0.5105756\\n  0.76409465 -0.0298513   1.5348257   0.22949617 -0.78020906  0.57496405\\n  0.4099166  -0.1186696   0.2062965  -0.46071377  0.6906902  -0.03765671\\n -0.07073653 -0.9857647  -0.50620484 -0.05078383 -0.72162324 -0.00578416\\n  0.52482826 -0.5540842  -0.44739988 -0.23272632  0.4711617  -0.23140244\\n -0.053135    0.3330895   0.29071632 -0.18335123  0.12409791 -0.5473938\\n  0.32626924  0.2834591  -0.29072145  0.2974172  -0.45938042 -0.2157086\\n  0.3270776  -0.5920965  -0.61349136 -0.03368954  0.40595973 -0.03168954\\n  0.10014092 -0.05219577 -0.44718885 -0.06090838  0.1702345  -0.04326385\\n  1.038797   -0.6585993  -0.11971456 -0.49773625  0.31438485  1.4334234\\n  0.8455228   0.6672888  -0.04093546 -0.00365115  0.40869203 -0.16525386\\n -0.55452746 -0.525207    0.45011273 -0.06517359 -0.7730654   0.4447964\\n  0.07087102 -0.29885355  0.4313868   0.16656536 -0.410875    0.9997892\\n  0.72036546 -0.00712222  0.35646686 -0.20307146  0.53396374 -0.6215885\\n -0.36461577 -0.692461    0.25810608 -0.44081712 -0.05549298  0.38468608\\n  0.29382113 -0.9476908   0.5181338  -0.7684582   0.55959636  0.22206974\\n  0.6038502   0.14563258 -0.47981158  0.23591302  0.39306006 -0.6406732\\n -0.50501484  0.6641791   0.06159039  0.8900619   0.18217783  0.0812566\\n  0.61948514 -0.27706513 -0.3920249   0.35147974 -0.13854432 -1.5782785\\n -0.15471175 -0.08140656 -1.1731868  -0.39798757 -0.62243897 -0.7765475\\n  0.0320375  -0.09037223 -0.54758143  0.9811267  -0.5325804   0.45725107\\n -0.6922059  -0.6004123  -0.11994451 -0.34955323  0.37626448  0.17879464\\n -0.06028037 -0.08054379  0.00290375  0.61527354 -0.13367508  0.5030862\\n  0.4808127  -0.02687675  0.6941738   0.27308783  0.3076968   0.01406422\\n  0.08770344  0.13813515  0.37205443 -0.5864895  -0.45760748  0.41531554\\n -0.5954323  -0.44664088 -1.0788212  -0.15643968  0.3797288   0.21190222\\n  0.44578838  0.22277248 -0.29073128  1.1567168   0.26154932 -0.8875659\\n  0.6140599   0.15473597 -0.6122668  -1.304542    0.8076616  -0.19628482\\n  0.6400044   0.40508017  0.21948843 -0.2561225  -0.26907185 -0.27500826\\n -0.0243019  -0.819495   -0.17491849 -0.6065145  -0.642026   -0.5388363\\n -1.0490221  -0.7443711  -0.5649721  -0.5510336  -0.5889802   0.24730064\\n  1.0492574   0.3413565   0.9181301  -0.65988696  0.27992892  0.17205407\\n  0.8315827  -0.6394326   0.3131007  -0.39434648 -0.4380933  -0.2994897\\n -0.8110466   0.00855087 -0.28132823 -0.13819766  0.39400578  0.01667863\\n  0.5629659   0.10021713  1.2005243   1.1641468  -1.2565438   0.32851115\\n -0.565998    0.20073934  1.20902     0.18444686 -0.46655586 -0.560195\\n -1.1869291  -0.90472776  0.3683177   0.43094578 -0.1779791  -0.05335245\\n -0.01473541  0.15383646  0.417688   -1.3414035  -0.5023896  -0.25280464\\n  0.01312735  0.08511329  0.20214666 -0.11293545 -0.5339131   0.6079277\\n -0.15051569  0.17398793  0.21536094 -0.05945035 -0.23195302 -0.04406474\\n  0.6541305   0.4770495  -0.99989194  0.43525097  0.37711546 -0.83348656\\n  0.79922396 -1.1209306  -0.25986055 -0.1426019   0.62625563  0.39228642\\n  0.52574605 -0.09534919 -0.10242816  0.10294192 -0.16325368 -0.51506996\\n  0.7014592   0.09043982 -0.34008935  0.02215129  0.42324898 -0.1093801\\n -1.3578445   0.4271373   0.21788399 -1.0122238  -0.63016623  0.9620865\\n  0.67177993 -0.29705647  0.5307099  -0.04989752 -0.5965302   0.79898983\\n  0.3341092   0.7369938   0.03607747  0.03802203  0.6668126   0.1184274\\n  0.78879404  0.43381318 -0.01394709 -0.86722976  0.3877015  -0.53335756\\n -0.4770054   0.03098146 -0.5088599   0.511716   -1.0448704  -0.21601391\\n  0.0169878   0.72458667 -0.3445269   0.64144975  0.16160558  0.9206863\\n -0.9326787   0.76664525  0.42752954 -0.75918823 -0.38591066 -0.6083426\\n  0.11969296 -0.4184498   0.8931784  -0.33748332 -1.0358292   0.14814311\\n -0.51768035 -0.8804209   0.8397574   0.34457013 -0.3500578   0.5388296\\n -0.07681358 -0.10798532 -0.39330086  0.46573174  0.5430047   1.0513847\\n  0.53523135  0.0637387  -0.38743934  0.0494298  -0.28867397  0.18985017\\n -1.3175645   0.64115757 -0.06278839 -0.64819545 -0.2866963   0.80061907\\n  0.1975023   0.39851227  0.8144428   0.580274    0.72493505 -0.10140654\\n  0.7110283  -0.42994407  0.2677717   0.7175706  -0.7346893   0.08232094\\n  0.63343066 -0.538388    0.785274    1.1167649   0.10489088  0.65957284\\n  0.31924048 -0.7342181   0.1718358  -0.06538925 -0.03996463  0.5776182\\n  0.11128387  0.33198515 -0.21451439 -0.3264586   0.34565315  0.31641397\\n -0.34395218  0.93607974  0.18080737 -0.4586376  -0.07290178 -0.10370082\\n  0.07697178 -0.83101106 -0.14314127  0.335247    0.02231645 -0.405346\\n -1.0351553   0.75837755 -0.6125285  -0.31811857 -0.20115297  0.38028634\\n -0.14418642 -0.82644445  0.8241987  -0.426905   -0.08164477  0.2738121\\n -0.40767658  0.23946516  0.24046671  0.1191034   0.13675722 -0.2658811\\n  0.26456776  0.52990454  0.84402543  0.5771873  -0.24597162 -0.68214875\\n  1.1510075  -1.2466726  -0.5366345  -0.5778473   0.11163926 -0.2462704\\n -0.5445793   0.40754023  1.1550528   0.48683563  0.11712318  0.6048615\\n -0.3899243  -0.13106634 -0.55239016  0.8438583  -0.40733492 -0.09361622\\n  0.189116   -1.1067048  -0.19320524  0.328671    0.45414624  0.0922756\\n  1.5566274   0.78955555  0.01403918  0.37781     0.5072066  -0.21294086\\n  0.5801      0.25908196  0.29380265 -0.30467013  0.17875598 -0.12220612\\n  0.18495484 -0.20048165 -1.0493706  -0.21502753 -0.46989885 -0.5876696\\n -0.7111187  -0.20773971  0.78117865  1.1579331  -1.2003679  -0.32569048\\n -0.6242537   0.5922249   0.11773336 -0.1150409   0.39635554 -0.12840636\\n -0.6534078   0.1577938   0.9171128   0.3148974   0.05785102 -0.20509173\\n -0.10461929  0.29787436  0.49198356  0.48421896 -0.4707284  -0.8933809\\n -0.15880503 -0.08948653  0.34732425  1.1944251  -0.09798714  0.495128\\n  0.55196005  0.48796082  1.0183401   0.25428632  0.7759278  -0.5850751\\n  0.62805194  0.62800735  0.57079357  0.03793677 -1.0180486   0.8038853\\n  0.44753918 -0.70651466 -0.45490995  0.27425656 -1.6353515  -0.9648935\\n  0.7416776   0.24388771 -0.60287005 -0.44661894 -0.31368634 -0.01810284\\n -0.4341623   0.33634982  1.5993981  -0.02008978 -0.3704299  -0.592792\\n  0.13962455  0.14716306 -0.86514395  0.14716385  0.55492043  0.4222927\\n  0.48438892  0.6174337  -0.3534061   0.03924527  0.68200845  0.40211412\\n -0.04644966 -0.7191321   0.09101206  0.20855677 -0.09225961 -0.35028425]\",\n          \"[ 1.21313035e-01 -9.08200204e-01  3.17704171e-01  6.13923788e-01\\n  1.26392528e-01  6.68054283e-01  2.86268350e-02 -5.79638302e-01\\n  6.69261456e-01  4.07688707e-01 -2.50783712e-01 -1.19380705e-01\\n -7.99364328e-01  1.33566856e-01 -4.47651744e-01  9.51432467e-01\\n -1.42341241e-01  2.36606598e-03  3.14735591e-01  4.33624871e-02\\n -4.67868477e-01 -4.00522709e-01 -9.82652187e-01 -6.31504953e-01\\n  9.13026273e-01 -4.31076670e-03  8.35599899e-01  1.95625737e-01\\n -2.77131706e-01  9.23748255e-01  2.88420051e-01 -1.25699893e-01\\n -2.98918217e-01  3.75047803e-01 -4.22812611e-01 -1.02894700e+00\\n -5.03140867e-01 -8.59567165e-01 -8.38678837e-01  5.01384676e-01\\n  3.40233237e-01  1.24498866e-01 -3.91699702e-01  8.14799726e-01\\n -4.38400030e-01  2.94911176e-01  1.47415251e-01 -1.40500546e-01\\n -2.83129960e-01  7.18580335e-02 -1.22500114e-01 -1.00502324e+00\\n  6.64687678e-02 -1.24496210e+00 -2.64272094e-03  2.30011269e-01\\n  1.00690162e+00 -1.07774734e-01 -4.62570429e-01 -1.02628636e+00\\n -6.97186291e-01  8.13354254e-01  2.65953571e-01  6.60751343e-01\\n  1.13163030e+00  6.65389597e-02 -2.71045089e-01 -8.29096317e-01\\n -1.83402061e-01 -3.00412983e-01  4.15197283e-01  3.67816418e-01\\n -1.55341521e-01 -3.59394580e-01 -6.16132200e-01  5.51902115e-01\\n -4.03000742e-01 -3.57987791e-01 -1.85159579e-01  2.51717448e-01\\n  2.58471340e-01  2.00812355e-01  7.21879780e-01 -1.78444330e-02\\n  3.20437759e-01  1.69095293e-01 -4.92550492e-01  8.41442570e-02\\n  6.34564877e-01  1.33179277e-01  1.93310931e-01  1.06415081e+00\\n -3.53811771e-01  8.45937252e-01  1.76986054e-01 -2.47254416e-01\\n  2.63395697e-01 -1.83722377e-01 -7.44918346e-01  4.84369129e-01\\n  2.23308727e-01  3.79848391e-01 -6.31665206e-03 -1.74342081e-01\\n  1.69057056e-01  5.80991924e-01 -2.92457670e-01 -5.27700245e-01\\n -9.79458392e-01  9.32162583e-01 -1.82767078e-01 -1.07869662e-01\\n  4.15511221e-01 -4.51917559e-01 -4.63384777e-01  1.04959169e-02\\n -4.12872881e-01 -2.40830883e-01 -5.12686908e-01  7.54446805e-01\\n -9.85227287e-01 -3.84341627e-01  4.34766680e-01 -1.28208637e+00\\n  4.84695107e-01  3.78355414e-01  3.15825731e-01 -4.03290009e-03\\n  1.76971301e-01 -7.57601082e-01  5.38086474e-01 -7.75382102e-01\\n  8.61454189e-01 -2.23790687e-02 -4.96957690e-01 -2.02983156e-01\\n  8.53470802e-01  7.13955402e-01 -7.65107453e-01  6.68469727e-01\\n -7.74779379e-01  2.86745489e-01 -5.17117023e-01 -3.09754252e-01\\n -5.15723288e-01  1.94875989e-02 -4.32975739e-01  8.99194777e-01\\n  8.46920013e-01 -3.26280862e-01  8.27402592e-01 -2.68477410e-01\\n -8.31737518e-01  5.57107031e-01 -1.61519453e-01 -7.03336522e-02\\n  1.51003629e-01 -1.61561266e-01 -3.25154424e-01 -3.49439949e-01\\n -1.80345595e-01 -3.44104767e-01 -3.18576455e-01  2.02115718e-02\\n  1.32410927e-02  7.89208412e-01  4.38525826e-01 -3.34492922e-01\\n -9.77041349e-02 -9.24409091e-01  2.11822037e-02  4.16572601e-01\\n -6.09741747e-01 -7.95225561e-01 -1.64356813e-01  1.75413474e-01\\n  1.18851840e-01  3.88792843e-01 -6.49469137e-01 -7.28539005e-02\\n -2.78455049e-01  5.56308091e-01  6.54752254e-01 -5.88355847e-02\\n  3.35914403e-01 -6.48157775e-01  3.93108934e-01  1.27982810e-01\\n  6.42431751e-02  5.73397577e-01 -3.13936591e-01 -8.38177919e-01\\n -1.53323993e-01  5.53015172e-01  7.42427409e-01 -6.50888026e-01\\n  6.95976555e-01  2.30246082e-01 -2.29808297e-02 -5.95162630e-01\\n  3.99918228e-01 -4.73264813e-01  2.95124412e-01 -4.02403206e-01\\n  2.77589750e-03 -7.04476297e-01 -7.57783711e-01  3.62922877e-01\\n -2.40644261e-01 -2.49164537e-01  6.89886093e-01  1.95007205e-01\\n -8.57568458e-02  6.72246635e-01 -7.43668795e-01 -5.15984118e-01\\n  2.59496033e-01  2.36543551e-01  4.44643259e-01  8.02149057e-01\\n  5.75980604e-01 -7.94152677e-01 -1.18169081e+00  6.04898512e-01\\n -1.02950491e-01  6.59175932e-01  4.97081876e-01  2.08942547e-01\\n  1.21795140e-01 -1.36853471e-01 -2.93393224e-01  7.29682446e-01\\n  8.65957737e-02 -4.45511192e-01  3.89698535e-01 -2.72947133e-01\\n  1.09458220e+00 -2.60978967e-01 -5.80830514e-01 -2.27921680e-01\\n  4.63252664e-02 -1.22789256e-01 -1.00336206e+00 -3.47736701e-02\\n -6.31054938e-02 -5.48287213e-01  9.57796872e-01 -7.22748995e-01\\n  7.61066303e-02 -6.62912846e-01 -3.50170702e-01  1.72866240e-01\\n  3.92061561e-01  3.12353045e-01  5.76015592e-01  7.24063575e-01\\n -1.14895153e+00  8.50511730e-01  4.44735736e-01 -2.46566311e-01\\n  7.46212542e-01 -9.41148698e-01  1.73258841e-01 -1.11491382e-01\\n -4.16243911e-01 -5.55048287e-01 -6.27782404e-01  3.81549485e-02\\n -7.75321305e-01 -3.15160483e-01  3.17907572e-01 -8.72824967e-01\\n -6.83192909e-01 -1.84921905e-01  6.97989613e-02  1.29749820e-01\\n -2.85020977e-01  7.69896209e-01  4.72186118e-01  2.29249313e-01\\n -4.63712931e-01 -1.23775482e+00  2.00042531e-01 -4.14098985e-02\\n -5.14768422e-01  1.90125212e-01 -3.22716743e-01 -3.75720114e-01\\n  5.26256442e-01 -4.67028946e-01 -3.08982104e-01 -1.12933554e-01\\n  3.90871525e-01 -3.97185951e-01 -5.19330621e-01 -5.50442338e-02\\n -4.65537399e-01  5.80011904e-02 -2.48926699e-01 -4.15855460e-02\\n  8.06665421e-01 -4.49344665e-01  1.32581070e-01 -3.18770677e-01\\n  3.19937199e-01  5.68560958e-01  4.01661783e-01  4.19390947e-01\\n  6.72730148e-01  2.75248885e-02 -3.72793764e-01 -7.48160407e-02\\n -1.95795134e-01 -4.59023625e-01  1.00419104e-01 -5.84542453e-01\\n -3.78110886e-01  4.07283872e-01  2.44753316e-01 -5.12210727e-01\\n -4.94094729e-01  3.21276546e-01 -2.24459305e-01  6.74492657e-01\\n  7.58785248e-01 -5.82994998e-01  7.61398792e-01  1.30141452e-01\\n  5.23415744e-01 -2.54214615e-01  1.81655586e-01 -4.27409261e-01\\n  2.29109168e-01 -2.53673673e-01 -8.13693479e-02 -2.82817602e-01\\n  1.95370629e-01 -5.60299098e-01  1.97694197e-01 -1.62878662e-01\\n  4.56364185e-01  6.69568002e-01  8.56758595e-01  6.64787665e-02\\n -9.48420465e-02  5.79136848e-01  4.13740158e-01 -9.10555363e-01\\n -9.52146575e-02  7.27163255e-01  2.35296175e-01  8.67719352e-01\\n  1.54239789e-01  2.07499221e-01  1.62823901e-01  9.76702049e-02\\n  5.60137816e-02  1.44299731e-01 -6.78653657e-01 -1.11857390e+00\\n  1.82791799e-02 -1.03184551e-01 -1.16226280e+00 -5.17015040e-01\\n -1.30984738e-01 -9.59278584e-01 -1.46913573e-01 -2.92613417e-01\\n -6.45476639e-01  5.43999732e-01 -7.52985716e-01  5.84435284e-01\\n -9.26893234e-01 -8.58123302e-01  2.33233139e-01 -1.88681558e-01\\n  5.21338165e-01  6.98694229e-01  2.69723028e-01 -3.66892666e-01\\n -1.87514246e-01  8.49725425e-01  1.56160876e-01  4.83971573e-02\\n  4.59177136e-01  1.69989362e-01  1.08723827e-01  5.12119830e-01\\n  3.47859621e-01  4.11054283e-01  9.92787257e-02 -5.30507863e-01\\n -6.56201765e-02 -5.74251711e-01 -8.48914146e-01  8.37714136e-01\\n -3.17605853e-01 -7.52134621e-01 -4.81002480e-01 -8.11578929e-01\\n  1.11414783e-01  2.42345348e-01  1.56562537e-01  2.23378256e-01\\n  5.50774448e-02  6.93292856e-01  5.98267496e-01 -4.26954776e-01\\n  5.79818249e-01  2.39424989e-01 -9.49594736e-01 -1.24350441e+00\\n  9.27816868e-01 -2.60387361e-02  1.38414070e-01  2.49198094e-01\\n  5.77186830e-02 -2.37213895e-01  1.11901976e-01 -5.53374946e-01\\n  3.60562474e-01 -5.84713995e-01 -2.74536218e-02 -3.76543075e-01\\n -1.55657500e-01 -6.41676784e-01 -8.06445897e-01 -5.29648304e-01\\n -4.02937263e-01 -7.82313526e-01 -6.09751165e-01  1.16753681e-02\\n  6.97668552e-01 -8.30012634e-02  4.67275351e-01 -6.28195107e-01\\n  2.37558722e-01  5.83278060e-01  9.04630959e-01 -1.01582728e-01\\n  2.40842536e-01  1.75791338e-01 -5.39134502e-01 -1.01393841e-01\\n -6.28593862e-01  3.69338006e-01 -6.75004303e-01 -2.00008750e-02\\n  7.40643561e-01  4.98243868e-02  4.72615570e-01  3.76268744e-01\\n  1.04627621e+00  1.07276165e+00 -5.49325526e-01  4.85553861e-01\\n -4.02334243e-01  1.75780535e-01  7.62236834e-01  5.72726786e-01\\n -3.14444035e-01 -3.22604865e-01 -1.02049994e+00 -5.42202890e-01\\n  1.71461105e-01  3.13701183e-02 -2.17096165e-01 -1.39599845e-01\\n -7.19120681e-01  1.48049727e-01  8.40461195e-01 -1.06782472e+00\\n -7.32989788e-01  3.09811234e-02 -7.63734162e-04 -2.48589516e-02\\n  1.64273039e-01 -5.35237491e-01 -4.03955251e-01  7.55744696e-01\\n  4.75062221e-01 -2.99689531e-01  1.43905997e-01 -1.75569132e-02\\n -6.23098850e-01 -2.23458603e-01  3.65828544e-01  9.60181713e-01\\n -7.53242314e-01  6.46491408e-01 -3.40725690e-01 -4.15747672e-01\\n  5.98140538e-01 -4.18778688e-01 -5.40806890e-01 -3.17216367e-02\\n -9.55288392e-03  1.60702839e-01  2.56949931e-01 -7.53398001e-01\\n -1.33226901e-01 -3.67357492e-01 -1.46894380e-01 -2.47959197e-02\\n  5.26151657e-01  3.88247579e-01 -5.27943159e-03  2.88474679e-01\\n -2.53096342e-01 -2.41271898e-01 -1.20096040e+00  6.23091877e-01\\n  6.16220646e-02 -7.81697094e-01 -1.13580622e-01  6.96595490e-01\\n  4.10103559e-01 -6.14106774e-01  4.68291014e-01  6.11955583e-01\\n -3.50003481e-01  7.62288332e-01  6.09262407e-01  5.24313033e-01\\n -3.24385643e-01  4.68716621e-01  4.15594816e-01  1.60957024e-01\\n  2.76718706e-01  1.69656262e-01  2.56384283e-01 -1.01335180e+00\\n  6.91116631e-01 -5.64415634e-01  3.05566698e-01  2.95427442e-01\\n -3.09355974e-01  1.71554163e-01 -3.87197644e-01 -2.04595760e-01\\n -2.18442932e-01  8.39740455e-01 -3.59202743e-01  5.33305824e-01\\n -1.32958844e-01  9.99399662e-01 -8.88631642e-01  8.21496725e-01\\n  9.06061947e-01 -7.67218888e-01 -1.15486868e-01 -5.50983131e-01\\n -1.55636653e-01 -3.99250537e-01  8.07243168e-01 -4.25608486e-01\\n  6.45560538e-03 -3.21172982e-01 -8.69467258e-02 -8.97455692e-01\\n  7.84899414e-01  1.65264234e-01 -1.49969056e-01  2.06933215e-01\\n  1.33944526e-01 -3.22194770e-02 -9.20197442e-02  6.10499859e-01\\n  1.17971337e+00  8.19690943e-01  2.98229065e-02 -6.59495413e-01\\n -6.85046017e-01  1.02827447e-02 -2.73195654e-01 -6.45330921e-02\\n -1.08315372e+00  9.07773733e-01  3.75024348e-01 -3.58234525e-01\\n -2.75856107e-01  1.15204132e+00  6.99662626e-01  2.34848782e-01\\n  4.77189064e-01  6.12811387e-01  7.71475375e-01 -2.65588284e-01\\n  7.92837858e-01  1.13675259e-01 -1.64262518e-01  1.14653099e+00\\n -3.55207920e-01 -1.73550144e-01  7.16834605e-01 -3.65617484e-01\\n  6.62070513e-01  1.43764555e+00  2.05674872e-01  1.11987972e+00\\n  6.52804792e-01 -2.60094047e-01  2.62114733e-01 -4.52119857e-01\\n -1.64147452e-01 -2.13056922e-01  1.65227279e-01  2.14883182e-02\\n -5.16454935e-01  3.41864347e-01  3.43903333e-01  2.04200506e-01\\n -6.45350397e-01  5.00977993e-01  2.27260515e-01 -5.06274343e-01\\n  1.97053075e-01 -3.39276522e-01  5.59560955e-02 -6.35118425e-01\\n  9.35374498e-02 -2.86231756e-01 -3.10120229e-02 -2.08680078e-01\\n -6.81364596e-01  2.40306377e-01 -5.95851481e-01 -4.34177160e-01\\n  1.83259711e-01  4.21207279e-01 -4.74199146e-01 -5.62427580e-01\\n  6.57522976e-01  4.27527614e-02 -2.36963704e-01  1.30405799e-01\\n -1.12686718e+00  6.11296356e-01  1.12193070e-01 -3.29951972e-01\\n  4.39648628e-01  4.69450474e-01  5.15453994e-01  7.86698341e-01\\n  2.19315901e-01  7.12720335e-01  6.91357180e-02 -1.73136055e-01\\n  9.12276089e-01 -9.05980527e-01 -9.74145174e-01 -5.13954580e-01\\n  2.29973376e-01 -7.16217384e-02 -7.59946644e-01  9.28119481e-01\\n  9.95964110e-01  3.34712058e-01 -2.92793036e-01  7.82764673e-01\\n -6.87863171e-01 -1.03521347e-01 -2.90423125e-01  5.27374744e-01\\n -6.63850248e-01 -4.81872797e-01  2.53572553e-01 -6.67078674e-01\\n -4.04458553e-01  2.73894191e-01 -1.30138278e-01 -2.04076543e-01\\n  1.20387685e+00  8.43445539e-01 -2.21668735e-01  1.02601081e-01\\n  4.20359343e-01 -9.59458351e-02  1.10764660e-01  6.15054071e-01\\n  8.74549150e-01 -9.52878296e-01  1.58113297e-02 -9.51168761e-02\\n -3.01317781e-01 -2.35334769e-01 -7.54135370e-01 -3.25036973e-01\\n -5.23765266e-01 -3.21920514e-01 -6.30017698e-01  3.11704781e-02\\n  3.43347579e-01  1.18183470e+00 -1.19373810e+00 -6.44941866e-01\\n -3.64029296e-02  8.09008539e-01 -1.73377350e-01 -3.51116061e-02\\n  4.96946603e-01 -1.52593732e-01 -8.45798433e-01  5.11155903e-01\\n  8.83879006e-01  1.12344928e-01  2.21428201e-01 -2.67071396e-01\\n -5.23050070e-01  3.53864670e-01  7.11203754e-01  5.77195346e-01\\n -9.85000908e-01 -8.98997784e-02 -1.64394557e-01  8.38669762e-02\\n  5.80266297e-01  8.87518108e-01 -4.03366983e-03  1.42532736e-01\\n  1.23500496e-01  5.99868119e-01  9.64701831e-01  3.57263327e-01\\n  5.80972612e-01 -2.42186710e-01  5.38839042e-01  2.23903894e-01\\n  3.02914053e-01 -1.62455246e-01 -8.93429101e-01  7.09423006e-01\\n  2.98295945e-01 -7.13425457e-01 -6.90406799e-01 -4.75089662e-02\\n -1.40799284e+00 -1.04633474e+00  8.32552254e-01 -6.05401658e-02\\n -1.62284935e+00 -5.36439121e-01 -9.31308642e-02 -3.19572002e-01\\n -5.72503030e-01  5.16265094e-01  1.10655832e+00 -4.10950899e-01\\n -2.45852351e-01 -9.28332806e-01  4.71279770e-01  7.50880390e-02\\n -8.68843138e-01 -1.31481573e-01  3.73685092e-01  8.11435044e-01\\n  3.22650671e-01  9.03646171e-01 -5.09946980e-02  5.19579530e-01\\n  5.35329580e-01 -1.84046868e-02 -5.86177818e-02 -5.55332482e-01\\n  3.40639740e-01  7.49888003e-01 -2.27320448e-01 -5.95343053e-01]\",\n          \"[ 1.90639094e-01 -7.63770103e-01  6.54947758e-01  5.34188092e-01\\n -3.33204418e-01  5.68458259e-01 -6.98729157e-02 -5.37290633e-01\\n  4.51758236e-01  7.08619833e-01 -3.96249324e-01 -6.34333044e-02\\n -1.09959924e+00  2.82825142e-01 -2.06087992e-01  8.55409563e-01\\n -4.69682328e-02 -2.18393398e-03  1.63528129e-01  2.46066842e-02\\n -8.71974885e-01 -1.53740644e-01 -1.41745985e+00 -9.27386761e-01\\n  8.76331508e-01  6.15035474e-01  8.68566811e-01 -9.41749811e-02\\n  4.44507241e-01  1.01882315e+00  4.45207924e-01 -1.64289370e-01\\n -3.80719900e-01  4.17122036e-01 -1.51921973e-01 -1.09923053e+00\\n  6.58667600e-03 -5.75843155e-01 -5.45822680e-01  7.27907479e-01\\n  5.88191867e-01  3.30653280e-01 -1.41736984e-01  9.40018952e-01\\n -4.01429504e-01  6.72783196e-01 -1.52165353e-01  6.76410720e-02\\n  9.22733173e-02  1.82431508e-02 -3.72623116e-01 -4.62339789e-01\\n -2.62337625e-01 -1.22625279e+00 -2.48662695e-01  3.66764069e-01\\n  1.24942744e+00  3.67851585e-01 -3.01581562e-01 -3.72970939e-01\\n -1.11398268e+00  9.34947014e-01  1.55813232e-01  5.94976723e-01\\n  1.04204273e+00  3.73720855e-01 -3.14877480e-01 -1.17568302e+00\\n -5.36245167e-01  7.06490204e-02 -3.41363847e-02  5.39451361e-01\\n -1.97548136e-01 -2.44024262e-01 -2.88504511e-01  4.57244486e-01\\n -2.15707183e-01 -5.65822124e-01 -2.45142817e-01  5.60577691e-01\\n  2.01602742e-01  3.62676054e-01  5.84157586e-01  2.57789880e-01\\n  6.77271187e-03  3.18582326e-01 -2.03586102e-01 -2.57541388e-01\\n  4.51675922e-01  3.29637051e-01  4.80731390e-02  6.29132807e-01\\n -4.81902927e-01  6.48401558e-01 -2.42613435e-01 -4.20366406e-01\\n  2.54369408e-01 -8.81252512e-02 -5.27374089e-01  2.84506232e-01\\n  3.87238503e-01  4.18001175e-01  1.00855231e-01 -4.83827114e-01\\n  1.39004827e-01  6.63151741e-01 -3.37521404e-01 -6.92190170e-01\\n -8.68205249e-01  1.03637266e+00 -4.16546464e-01  4.32189219e-02\\n  2.60433614e-01 -5.81282616e-01 -5.90729117e-01 -4.63938475e-01\\n -6.74196780e-02  7.82643706e-02 -4.03571695e-01  6.68024480e-01\\n -1.35664165e+00 -3.15754056e-01  5.77346087e-01 -1.06445539e+00\\n  5.93335569e-01  3.59105438e-01  6.19115770e-01 -1.50148228e-01\\n  5.16799033e-01 -7.34040201e-01  4.82226759e-01 -3.74420851e-01\\n  1.06677282e+00 -3.07132185e-01 -6.81370914e-01  3.81344169e-01\\n  6.71876192e-01  3.52713078e-01 -3.48452955e-01  1.15604198e+00\\n -3.54300886e-01  6.28419936e-01 -7.47619152e-01 -2.41541326e-01\\n -3.14288884e-01  6.55479059e-02 -2.58237153e-01  1.11719310e+00\\n  6.58661366e-01 -6.12147748e-01  8.00290585e-01 -1.05860221e+00\\n -9.09494221e-01  5.89890301e-01 -1.24596983e-01 -3.10339302e-01\\n -3.87136936e-02 -2.66699940e-01 -1.84122160e-01  3.10665607e-01\\n -2.76797801e-01 -3.11237067e-01 -4.49315429e-01  1.63634941e-02\\n  3.12768191e-01  8.33218992e-01  7.32555091e-01 -2.45533332e-01\\n -3.43073845e-01 -1.10027122e+00  1.07819699e-01  3.40806961e-01\\n -3.15512627e-01 -3.25941205e-01  1.08779795e-01 -1.36542795e-02\\n  1.16507448e-01  2.06463143e-01 -9.63856041e-01  6.52704388e-02\\n  3.36093694e-01  7.52896965e-01  3.40339512e-01  2.03647807e-01\\n  1.02034129e-01 -5.70508778e-01  1.44498482e-01  9.65380296e-02\\n  1.77590787e-01  1.76759914e-01 -5.11130869e-01 -1.10530603e+00\\n -5.18220842e-01  4.67296034e-01  7.90458977e-01 -4.35560614e-01\\n  6.67799890e-01 -2.43041679e-01 -3.57315689e-01 -6.31604195e-01\\n  1.75432160e-01 -2.70503014e-01  4.28950161e-01 -7.52933547e-02\\n -4.48290445e-02 -5.73345006e-01 -7.66204119e-01  7.50831887e-02\\n -5.27032018e-02 -2.04862654e-01  6.28716767e-01  3.33586663e-01\\n -2.06101969e-01  4.70414549e-01 -1.07337761e+00 -9.39507246e-01\\n  1.76999331e-01  2.16363713e-01  4.44701910e-01  5.73836327e-01\\n  5.62640309e-01 -5.19340575e-01 -1.03628826e+00  2.11302206e-01\\n -9.66289937e-02  4.22745436e-01  4.01973873e-01 -9.97591391e-02\\n -1.89374253e-01  1.46910017e-02 -3.50021094e-01  6.35106564e-01\\n -1.02962814e-01 -5.29126823e-01  3.67512852e-01 -1.05683088e-01\\n  1.06916046e+00 -6.18629694e-01 -2.93762475e-01 -5.59071541e-01\\n -4.22187179e-01 -4.16098595e-01 -9.51246500e-01 -3.84397388e-01\\n -4.56282824e-01 -5.18233120e-01  6.81224108e-01 -6.49076045e-01\\n  8.50427970e-02 -9.44030941e-01 -4.20108765e-01  5.97449601e-01\\n  2.45547965e-01  4.15204495e-01  6.35453701e-01  6.17176175e-01\\n -7.45957851e-01  4.13260967e-01  4.85946566e-01 -1.17870867e-01\\n  8.04335415e-01 -9.03144300e-01  4.55220610e-01 -1.41775832e-01\\n -1.94288924e-01 -1.35659277e+00 -3.97439092e-01  4.29546595e-01\\n -5.49261391e-01 -2.36130536e-01  1.96350023e-01 -8.18058491e-01\\n -4.26917553e-01  2.63667643e-01 -2.93183684e-01  3.73092033e-02\\n -2.72421479e-01  5.30385256e-01  1.93110630e-01 -6.31487370e-03\\n -4.38289613e-01 -9.92043793e-01  2.03155592e-01 -1.45133391e-01\\n -4.72280353e-01  7.53161823e-03  3.50792445e-02 -6.99917495e-01\\n  4.06483501e-01 -2.68594027e-02 -4.51366156e-01  3.71072628e-02\\n  8.03896010e-01 -6.56797171e-01 -3.79600137e-01  2.05967948e-01\\n -5.07566869e-01 -2.20946446e-01 -1.00353099e-01  1.62596568e-01\\n  6.94038332e-01 -2.18381926e-01  2.57461041e-01 -6.67805195e-01\\n  6.98250592e-01  6.23406112e-01  4.87056494e-01  5.60198784e-01\\n  8.47552240e-01 -7.97995925e-02 -1.29735889e-02 -7.44735003e-02\\n -1.34554310e-02 -5.41921079e-01 -1.22818559e-01 -5.38252056e-01\\n -3.11670333e-01  4.86580610e-01 -2.12499782e-01  1.57692339e-02\\n -2.13029400e-01  1.01621740e-01 -4.17471290e-01  4.56293672e-01\\n  5.83774388e-01 -4.14547294e-01  7.33866453e-01  3.49497229e-01\\n  1.07365286e+00 -2.09121510e-01 -1.04271062e-01 -1.12356937e+00\\n -6.23986661e-01 -1.23069070e-01 -2.43740812e-01 -1.57249033e-01\\n -3.94623160e-01 -6.82692289e-01 -6.80846646e-02 -1.98286787e-01\\n  5.98133624e-01  8.61643851e-01  4.33233410e-01  1.81302235e-01\\n -2.53405899e-01  5.44364631e-01  1.49045095e-01 -3.78416777e-01\\n -3.11598986e-01  4.07893270e-01  2.19869390e-01  8.31053793e-01\\n -6.62169233e-02  3.01780283e-01  3.12635452e-01 -4.14863490e-02\\n -6.61550701e-01  9.26161632e-02 -3.76143605e-01 -1.04353189e+00\\n  8.98444578e-02  1.25948176e-01 -1.25344896e+00 -3.37657601e-01\\n -5.44437587e-01 -6.13493621e-01 -1.27641052e-01 -5.62505186e-01\\n -5.16728878e-01  3.55892926e-01 -8.99880707e-01  5.00984371e-01\\n -3.57016444e-01 -7.68292010e-01  4.09340143e-01 -3.21979672e-01\\n  4.55496401e-01  7.45267928e-01  1.86637416e-01 -4.47799116e-01\\n  3.16268392e-02  5.17317772e-01 -3.30649763e-02  4.12214212e-02\\n  8.54837671e-02  5.16726077e-01 -1.43985695e-03  2.14484096e-01\\n  4.16287452e-01  2.20783949e-01  4.00434947e-03 -3.91773492e-01\\n -4.31816792e-03 -8.21863174e-01 -9.51705933e-01  8.65427554e-01\\n -4.01747078e-01 -9.14327800e-01 -5.58625937e-01 -5.29458582e-01\\n -9.42122117e-02  2.42209375e-01  2.43730024e-01  1.04825599e-02\\n -2.64862210e-01  6.57966256e-01  4.08626795e-01 -7.43379369e-02\\n  6.57698512e-01  2.42370486e-01 -5.51962614e-01 -8.83448303e-01\\n  5.72526455e-01 -1.28105476e-01  7.84799531e-02  3.22426736e-01\\n  7.01861456e-02 -2.40850404e-01 -5.82252629e-02 -5.34421027e-01\\n -1.68735966e-01 -4.53982711e-01  5.80844795e-03 -7.18667269e-01\\n -1.73802063e-01 -7.50811756e-01 -5.19971907e-01 -7.02552378e-01\\n -8.76642048e-01 -5.65540612e-01 -6.98673785e-01  2.79560059e-01\\n  6.95455849e-01  2.98415989e-01  1.27094471e+00 -5.74209869e-01\\n -2.07262132e-02  1.80222571e-01  5.54743946e-01 -6.75105095e-01\\n -5.64395189e-02 -3.00103035e-02 -8.94732177e-01 -4.63246435e-01\\n -3.77072662e-01  1.09968819e-01 -8.55063796e-02 -4.53814119e-01\\n  1.20795476e+00 -1.98846772e-01  4.30891126e-01 -2.60590285e-01\\n  1.45189607e+00  9.73708332e-01 -2.12996647e-01  5.15214980e-01\\n -5.11220515e-01  2.59604484e-01  1.26334572e+00  4.90787238e-01\\n -4.10306573e-01 -3.42825502e-01 -1.08633709e+00 -4.92045492e-01\\n -2.57738143e-01  2.68620908e-01  2.46274635e-01 -3.40661295e-02\\n -3.43299836e-01  4.14211266e-02  5.54550588e-01 -5.92218459e-01\\n -5.35232604e-01 -1.13745183e-02  2.38586828e-01  2.62362093e-01\\n  7.41418973e-02 -3.91716689e-01 -4.48119789e-01  7.91621685e-01\\n  5.39583445e-01  8.07423424e-03  3.49906683e-01  4.21631008e-01\\n -3.88755351e-01 -4.27980125e-02  3.40482861e-01  6.80543244e-01\\n -5.16659677e-01  6.83046103e-01 -2.31451139e-01 -4.80876118e-01\\n  5.49372375e-01 -5.00145912e-01 -3.62764746e-01  8.01964343e-01\\n -1.17013842e-01  6.98026717e-01  3.09051543e-01 -2.15527222e-01\\n -2.01284453e-01 -6.67793036e-01 -1.85126022e-01 -3.85049909e-01\\n  7.94443607e-01  2.05985382e-01 -2.09008396e-01 -1.81123614e-04\\n  4.78249751e-02 -9.18686669e-03 -1.11611366e+00  5.15671194e-01\\n  2.12407902e-01 -1.12175310e+00 -2.57971734e-02  6.61772490e-01\\n  6.02824867e-01 -9.51173306e-01  3.37830871e-01  5.08056700e-01\\n -3.07426095e-01  1.47220269e-01  4.85496372e-01  5.90664625e-01\\n -9.72890258e-02  3.49147707e-01  5.92135906e-01 -1.10701174e-01\\n  2.20422223e-01  4.46782500e-01  7.16559812e-02 -9.56855595e-01\\n  7.08403826e-01 -6.01618946e-01 -3.64226073e-01  6.54427767e-01\\n -2.94358164e-01  4.98497993e-01 -4.95372415e-01 -6.18272185e-01\\n  2.86815017e-01  1.09211648e+00 -5.46660900e-01  5.14950514e-01\\n -4.46470976e-02  9.75056648e-01 -1.08704376e+00  8.12686026e-01\\n  7.81426191e-01 -5.83532572e-01 -1.66955709e-01 -4.18592006e-01\\n -2.29699746e-01 -5.61939776e-01  5.47627985e-01 -1.32705286e-01\\n -3.39089990e-01 -2.79604226e-01 -2.73791403e-01 -5.63213050e-01\\n  4.84364390e-01  1.54987752e-01 -2.72714853e-01  6.35874808e-01\\n  5.70862770e-01  1.04148008e-01 -1.92329124e-01  5.96684396e-01\\n  1.06724179e+00  8.78931224e-01  3.91297229e-02 -1.25251517e-01\\n -4.54137892e-01 -5.46402223e-02 -2.60425448e-01  2.20400244e-02\\n -1.42362630e+00  2.82071680e-01  2.03243554e-01 -1.38923511e-01\\n -2.42979988e-01  1.06908858e+00  9.79483798e-02  1.39445707e-01\\n  8.39309931e-01  1.03864384e+00  9.28233802e-01 -4.17766124e-01\\n  7.10930169e-01 -8.42327904e-03 -4.36732620e-01  1.12357819e+00\\n -6.33984566e-01  1.18584096e-01  9.58271801e-01 -6.46180153e-01\\n  7.34497726e-01  1.03752005e+00  1.39928386e-01  8.21477413e-01\\n  2.98297614e-01 -6.39780581e-01  9.99706611e-02 -6.46418989e-01\\n -1.34487614e-01  8.54654517e-03  2.21498445e-01 -4.61665869e-01\\n -2.96635687e-01 -1.08000733e-01  6.28591001e-01  4.64404255e-01\\n -1.13137476e-01  6.53126776e-01  3.44624847e-01 -7.46680975e-01\\n  1.01307400e-01 -4.53825951e-01 -3.94474268e-01 -7.02027559e-01\\n  4.99207973e-02 -1.23022385e-01  1.56602427e-01 -1.81405291e-01\\n -5.33573449e-01  3.67042452e-01 -5.81087410e-01 -5.37104309e-01\\n -1.09852351e-01  9.98245060e-01 -3.79187703e-01 -8.09279621e-01\\n  2.69076526e-01 -8.54695439e-02  9.49233249e-02 -1.91253517e-02\\n -7.69437134e-01  3.40765864e-01 -2.84888208e-01  7.81635642e-02\\n  1.09957397e-01  5.42952836e-01  9.24576461e-01  4.42471653e-01\\n  4.20468807e-01  6.89051807e-01 -3.37124877e-02 -6.25044554e-02\\n  6.74782515e-01 -5.63263237e-01 -7.35447586e-01 -5.53738832e-01\\n  7.15729520e-02 -3.44784409e-01 -9.48822677e-01  8.73147786e-01\\n  8.89906585e-01  1.11825377e-01 -2.55414605e-01  8.48927259e-01\\n -2.25395337e-01  1.07353948e-01 -7.58074000e-02  8.81183326e-01\\n -2.61125326e-01 -8.10570300e-01  1.82848379e-01 -7.31926143e-01\\n -4.35961962e-01  3.53629589e-01 -1.51018500e-01 -4.92686272e-01\\n  1.08426762e+00  6.48900032e-01 -1.13942683e-01  5.52985251e-01\\n  3.42942327e-01 -2.08615020e-01  2.12820098e-01  2.65782982e-01\\n  6.68609202e-01 -8.08864534e-01  7.75328055e-02  8.02783594e-02\\n -2.13699818e-01 -1.85246021e-02 -6.72870159e-01 -6.48187160e-01\\n -3.79958153e-01 -5.74851692e-01 -6.96226776e-01  5.49330004e-02\\n  5.29530466e-01  1.07640362e+00 -1.09717131e+00 -1.45821676e-01\\n  3.67712349e-01  3.64050895e-01 -3.65605950e-01 -1.06793366e-01\\n  3.34323406e-01 -9.27456379e-01 -1.12785780e+00  4.62249726e-01\\n  6.74972773e-01 -3.43416780e-01  3.33260149e-01  2.63997376e-01\\n -3.12844843e-01  1.75242141e-01  7.12644577e-01  3.86161715e-01\\n -1.29020095e-01 -3.72797012e-01 -2.51937866e-01  1.76519454e-01\\n  9.14028883e-01  8.51124823e-01  1.75644159e-02  3.51389527e-01\\n  5.49127758e-01  5.84568262e-01  7.33880460e-01  3.56047124e-01\\n  5.72037697e-01 -3.81998390e-01  8.33396435e-01  3.62126201e-01\\n  6.61141336e-01  4.26672250e-02 -9.54921067e-01  6.06898487e-01\\n  6.82646334e-01 -9.11304772e-01 -6.50633693e-01  2.35479951e-01\\n -1.33302140e+00 -5.03212273e-01  9.89296257e-01 -4.81963158e-01\\n -1.30880833e+00 -7.88967371e-01 -9.62456688e-02 -1.06237464e-01\\n -7.01827049e-01  8.99839401e-01  1.26649189e+00 -4.67010736e-01\\n  2.00764880e-01 -9.41659153e-01  6.72762454e-01  3.49424988e-01\\n -7.37306356e-01 -2.51963586e-01  3.75242978e-01  9.30973351e-01\\n  1.85798600e-01  1.01658070e+00 -4.70372997e-02  9.99620855e-02\\n  5.35451829e-01 -2.86941797e-01 -9.71875116e-02 -4.97621894e-01\\n  7.08706796e-01  2.61494905e-01 -3.59750509e-01 -1.15745318e+00]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2WjqR_PzMtg"
      },
      "source": [
        "# Semantic Search\n",
        "\n",
        "Now that we have our word embeddings stored, let's load them into a new dataframe and use it for semantic search. Since the 'embedding' in the CSV is stored as a string, we'll use apply() and to interpret this string as Python code and convert it to a numpy array so that we can perform calculations on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yM6N30oYeWhs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "outputId": "dc870c89-de00-4c5b-b152-42dc849add87"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Perhaps you forgot a comma? (<string>, line 1)",
          "traceback": [
            "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3553\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \u001b[1;32m\"<ipython-input-10-b7757f2a9b1e>\"\u001b[0m, line \u001b[1;32m4\u001b[0m, in \u001b[1;35m<cell line: 0>\u001b[0m\n    df['embedding'] = df['embedding'].apply(eval).apply(np.array)\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\"\u001b[0m, line \u001b[1;32m4924\u001b[0m, in \u001b[1;35mapply\u001b[0m\n    ).apply()\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\"\u001b[0m, line \u001b[1;32m1427\u001b[0m, in \u001b[1;35mapply\u001b[0m\n    return self.apply_standard()\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\"\u001b[0m, line \u001b[1;32m1507\u001b[0m, in \u001b[1;35mapply_standard\u001b[0m\n    mapped = obj._map_values(\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.11/dist-packages/pandas/core/base.py\"\u001b[0m, line \u001b[1;32m921\u001b[0m, in \u001b[1;35m_map_values\u001b[0m\n    return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.11/dist-packages/pandas/core/algorithms.py\"\u001b[0m, line \u001b[1;32m1743\u001b[0m, in \u001b[1;35mmap_array\u001b[0m\n    return lib.map_infer(values, mapper, convert=convert)\n",
            "\u001b[0;36m  File \u001b[0;32m\"lib.pyx\"\u001b[0;36m, line \u001b[0;32m2972\u001b[0;36m, in \u001b[0;35mpandas._libs.lib.map_infer\u001b[0;36m\u001b[0m\n",
            "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    [-0.45700905  0.08197942  0.39368343  0.6244858  -0.2658719   0.22609822\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('word_embeddings.csv')\n",
        "df['embedding'] = df['embedding'].apply(eval).apply(np.array)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCtyD-yZz-6W"
      },
      "source": [
        "Let's now prompt ourselves for a search term that isn't in the dataframe. We'll use word embeddings to perform a semantic search for the words that are most similar to the word we entered. I'll first try the word \"hot dog\". Then we'll come back and try the word \"yellow\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtyaOReqzzn3"
      },
      "outputs": [],
      "source": [
        "search_term = input('Enter a search term: ')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpFRGaAX0H82"
      },
      "source": [
        "Now that we have a search term, let's calculate an embedding or vector for that search term using the OpenAI get_embedding function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrm5cxdDzfgU"
      },
      "outputs": [],
      "source": [
        "# semantic search\n",
        "search_term_vector = get_embedding(search_term)\n",
        "search_term_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVSNY0Ci0hB5"
      },
      "source": [
        " Once we have a vector representing that word, we can see how similar it is to other words in our dataframe by calculating the cosine similarity of our search term's word vector to each word embedding in our dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: https://platform.openai.com/docs/guides/embeddings/use-cases"
      ],
      "metadata": {
        "id": "y7hL4A6B487u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
      ],
      "metadata": {
        "id": "6UMIUUSg8C_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhE3ATG80oAt"
      },
      "outputs": [],
      "source": [
        "df[\"similarities\"] = df['embedding'].apply(lambda x: cosine_similarity(x, search_term_vector))\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsqkYbCD05TC"
      },
      "source": [
        "# Sorting By Similarity\n",
        "\n",
        "Now that we have calculated the similarities to each term in our dataframe, we simply sort the similarity values to find the terms that are most similar to the term we searched for. Notice how the foods are most similar to \"hot dog\". Not only that, it puts fast food closer to hot dog. Also some colors are ranked closer to hot dog than others. Let's go back and try the word \"yellow\" and walk through the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_4bDAkOg2m7"
      },
      "outputs": [],
      "source": [
        "df.sort_values(\"similarities\", ascending=False).head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LnJhZLK2pgz"
      },
      "source": [
        "# Adding Words Together\n",
        "\n",
        "What's even more interesting is that we can add word vectors together. What happens when we add the numbers for milk and espresso, then search for the word vector most similar to milk + espresso? Let's make a copy of the original dataframe and call it food_df. We'll operate on this copy. Let's try adding word together. Let's add milk + espresso and store the results in milk_espresso_vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CD-_nVUhGBH"
      },
      "outputs": [],
      "source": [
        "food_df = df.copy()\n",
        "\n",
        "milk_vector = food_df['embedding'][10]\n",
        "espresso_vector = food_df['embedding'][19]\n",
        "\n",
        "milk_espresso_vector = milk_vector + espresso_vector\n",
        "milk_espresso_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's find the words most similar to milk + espresso. If you have never done this before, it's pretty surprising that you can add words together like this and find similar words using numbers."
      ],
      "metadata": {
        "id": "PxlPom9m4nLB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3UCdDmJjfaQ"
      },
      "outputs": [],
      "source": [
        "food_df[\"similarities\"] = food_df['embedding'].apply(lambda x: cosine_similarity(x, milk_espresso_vector))\n",
        "food_df.sort_values(\"similarities\", ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zfp3tgRsQHFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing the Vectors"
      ],
      "metadata": {
        "id": "g_GLWR9_QpTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configurations"
      ],
      "metadata": {
        "id": "lE_kZgwu4GaD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNaC9jGDmaPn"
      },
      "source": [
        "%pip install umap-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQGgGfioRskp"
      },
      "source": [
        "from __future__ import print_function\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Javascript, HTML\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris, load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import umap\n",
        "import codecs, json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo5EWvq8R2dj"
      },
      "source": [
        "sns.set(style='white', context='notebook', rc={'figure.figsize':(14,10)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_sr8x_ESFLD"
      },
      "source": [
        "reducer = umap.UMAP(init='random')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reducer"
      ],
      "metadata": {
        "id": "NRtIFainOLe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions Definition"
      ],
      "metadata": {
        "id": "m2HvaKAh4rOf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtLlRS59SHK_"
      },
      "source": [
        "def run_umap(data, n_neighbors, min_dis, n_components, metric, spread):\n",
        "  reducer.n_neighbors = n_neighbors\n",
        "  reducer.min_dist = min_dis\n",
        "  reducer.n_components = n_components\n",
        "  reducer.metric = metric\n",
        "  reducer.spread = spread\n",
        "  embedding = reducer.fit_transform(data)\n",
        "  return embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BfZota4SLpH"
      },
      "source": [
        "def make_viz_embed(data, color = [], labels = []):\n",
        "  embed = f\"\"\"\n",
        "    <div id=\"observablehq-viewof-containerEl-96fe8cff\"></div>\n",
        "    <script type=\"module\">\n",
        "    import {{Runtime, Inspector}} from \"https://cdn.jsdelivr.net/npm/@observablehq/runtime@4/dist/runtime.js\";\n",
        "    import define from \"https://api.observablehq.com/@radames/umap-jupyter-notebook-scattergl.js?v=3\";\n",
        "    const inspect = new Inspector(document.querySelector(\"#observablehq-viewof-containerEl-96fe8cff\"));\n",
        "    const notebook = (new Runtime).module(define, name => {{\n",
        "    if(name === \"viewof containerEl\") return inspect;\n",
        "        return [\"init\"].includes(name);\n",
        "    }})\n",
        "    notebook.redefine('points', {json.dumps(data,separators=(',', ':'))})\n",
        "    notebook.redefine('colors', {json.dumps(colors,separators=(',', ':'))})\n",
        "    notebook.redefine('labels', {json.dumps(labels,separators=(',', ':'))})\n",
        "    </script>\n",
        "\n",
        "  \"\"\"\n",
        "  return embed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag_Ppl3_aFIi"
      },
      "source": [
        "def render(data, colors, labels, n_neighbors=100, min_dis=0.5, n_components=3, metric='euclidean', spread = 1.0):\n",
        "  embedding = run_umap(data, n_neighbors, min_dis, n_components, metric, spread)\n",
        "  html_str = make_viz_embed(embedding.tolist(), colors, labels)\n",
        "  display(HTML(html_str))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data"
      ],
      "metadata": {
        "id": "hP8WdxyM4SoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "casos_uso_df = pd.read_csv('word_embeddings.csv')"
      ],
      "metadata": {
        "id": "uW6B2uULPJmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "casos_uso_df.embedding = casos_uso_df.embedding.apply(eval).apply(np.array)"
      ],
      "metadata": {
        "id": "KUdOtUcBcbym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "casos_uso_df"
      ],
      "metadata": {
        "id": "MO1j_9tGcgwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "casos_uso_df.embedding"
      ],
      "metadata": {
        "id": "Rgd3Gm_OTQTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapting for the expected data format\n",
        "\n",
        "output_list = list()\n",
        "for n in casos_uso_df.embedding:\n",
        "  inter_output_line = list()\n",
        "  for m in n:\n",
        "    inter_output_line.append(m)\n",
        "  output_list.append(inter_output_line)\n",
        "\n",
        "output_list[0:1]"
      ],
      "metadata": {
        "id": "td-fXR00UXPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colors = [sns.color_palette()[0] for x in output_list]\n",
        "colors"
      ],
      "metadata": {
        "id": "1_lQt6zoVp5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "3Fzbja_l6gJZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uU8Cvx4Sw5_"
      },
      "source": [
        "render(output_list, colors, casos_uso_df['Itens'].to_list(), n_neighbors=3, min_dis=0.5, n_components=3, metric='cosine')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}